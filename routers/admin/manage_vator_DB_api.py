from __future__ import annotations

from fastapi import APIRouter, Request, Body, status, Query, UploadFile, File, HTTPException, Form
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Optional, Dict, Literal, Any
import json as _json

from pymilvus.grpc_gen.common_pb2 import RequestTSO

from service.admin.manage_vator_DB import (
    TASK_TYPES,
    OverrideLevelsRequest,
    delete_collection,
    override_levels_and_ingest,
    # ì„¤ì •
    set_vector_settings,
    list_available_embedding_models,
    get_security_level_rules_all,
    upsert_security_level_for_task,
    get_security_level_rules_for_task,
    # íŒŒì´í”„ë¼ì¸
    ingest_embeddings,
    execute_search,
    # ê´€ë¦¬
    list_indexed_files,
    list_indexed_files_overview,
    delete_files_by_names,
    # íŒŒì¼ ì €ì¥
    process_saved_raw_files,
)
from service.preprocessing.rag_preprocessing import extract_documents
from storage.db_models import DocumentType
from utils import logger
from utils.documents import save_raw_file
from utils.model_load import get_vector_settings
router = APIRouter(
    prefix="/v1",
    tags=["Admin Document - RAG"],
    responses={
        status.HTTP_200_OK: {"description": "Successful Response"},
        status.HTTP_401_UNAUTHORIZED: {"description": "Unauthorized"},
        status.HTTP_403_FORBIDDEN: {"description": "Forbidden"},
        status.HTTP_404_NOT_FOUND: {"description": "Not found"},
    },
)
logger = logger(__name__)
# ============================
# Request/Response Models
# ============================

class VectorSettingsBody(BaseModel):
    embeddingModel: Optional[str] = Field(
        None,
        description="ì„ë² ë”© ëª¨ë¸ í‚¤ (ì˜ˆ: bge, embedding_bge_m3, qwen3_4b ë“±)"
    )
    searchType: Optional[Literal["hybrid", "semantic", "bm25"]] = Field(
        None,
        description="ê²€ìƒ‰ ë°©ì‹ (hybrid | semantic | bm25)"
    )
    chunkSize: Optional[int] = Field(
        None, ge=256, description="ì²­í¬ í† í° í¬ê¸° (ê¸°ë³¸ 512)"
    )
    overlap: Optional[int] = Field(
        None, ge=64, description="ì²­í¬ ê°„ ì˜¤ë²„ë© í† í° ìˆ˜ (ê¸°ë³¸ 64)"
    )


class TaskSecurityConfig(BaseModel):
    maxLevel: int = Field(..., ge=1, description="ìµœëŒ€ ë³´ì•ˆ ë ˆë²¨ (>=1)")
    # '@'ë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë„ í—ˆìš©(ë ˆê±°ì‹œ í˜¸í™˜)
    levels: Dict[str, str | List[str]] = Field(
        default_factory=dict,
        description="ë ˆë²¨ë³„ í‚¤ì›Œë“œ ì„¤ì •. '@' ë¬¸ìì—´ ë˜ëŠ” í‚¤ì›Œë“œ ë°°ì—´ ëª¨ë‘ í—ˆìš©",
        examples=[{"1": "@ì¼ë°˜@ê³µê°œ", "2": "@ì—°êµ¬@ì—°ë´‰", "3": "@ë¶€ì •"}]
    )


class SecurityLevelsBody(BaseModel):
    service: Optional[str] = Field(default="global", description="ì„œë¹„ìŠ¤ ì´ë¦„(ë“œë¡­ë‹¤ìš´)")
    # ì‘ì—…ìœ í˜•ë³„(doc_gen, summary, qna) ë³´ì•ˆì„¤ì •
    doc_gen: TaskSecurityConfig
    summary: TaskSecurityConfig
    qna: TaskSecurityConfig


class ExecuteBody(BaseModel):
    question: str = Field(..., examples=["íšŒì‚¬ì˜ ë¶€ì •ì²­íƒ ì œë„ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"])
    topK: int = Field(50, gt=0, description="ì„ë² ë”© í›„ë³´ ê°œìˆ˜")
    rerank_topN: int = Field(5, gt=0, description="ë¦¬ë­í¬ í›„ ìµœì¢… ë°˜í™˜ ê°œìˆ˜")
    securityLevel: int = Field(1, ge=1)
    sourceFilter: Optional[List[str]] = None
    taskType: Literal["doc_gen", "summary", "qna"]
    searchMode: Optional[Literal["hybrid", "semantic", "bm25"]] = None

    model_config = {
        "json_schema_extra": {
            "example": {
                "question": "íšŒì‚¬ì˜ ë¶€ì •ì²­íƒ ì œë„ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
                "topK": 50,
                "rerank_topN": 5,
                "securityLevel": 3,
                "sourceFilter": ["íšŒì‚¬ê·œì •.pdf", "ë³µë¦¬í›„ìƒì•ˆë‚´.pdf"],
                "taskType": "qna",
                "searchMode": "hybrid",
            }
        }
    }


class SingleIngestBody(BaseModel):
    pdfPath: str
    taskTypes: Optional[List[Literal["doc_gen", "summary", "qna"]]] = None
    workspaceId: Optional[int] = None


class DeleteFilesBody(BaseModel):
    filesToDelete: List[str] = Field(
        ...,
        description="ì‚­ì œí•  íŒŒì¼ ì´ë¦„ ë°°ì—´ (ì˜ˆ: ['ì‚¬ê·œ.pdf','ë³´ë„ìë£Œ_20240101.pdf'])",
        examples=[["íšŒì‚¬ë‚´ê·œ.pdf", "20240835_ë³´ê³ ì„œ.pdf"]],
    )
    taskType: Optional[Literal["doc_gen", "summary", "qna"]] = Field(
        None,
        description="ì§€ì • ì‹œ í•´ë‹¹ ì‘ì—…ìœ í˜• ë°ì´í„°ë§Œ ì‚­ì œ. ë¯¸ì§€ì • ì‹œ ì „ì²´ ì‘ì—…ìœ í˜•ì—ì„œ ì‚­ì œ"
    )

    model_config = {
        "json_schema_extra": {
            "example": {
                "filesToDelete": [
                    "81._ë¶€ì •ì²­íƒë°ê¸ˆí’ˆë“±ìˆ˜ìˆ˜ì˜ì‹ ê³ ì‚¬ë¬´ì²˜ë¦¬ì—ê´€í•œë‚´ê·œ_20191128.pdf"
                ],
                "taskType": "qna"
            }
        }
    }


# ============================
# Vector Settings
# ============================

@router.post(
    "/admin/vector/settings",
    summary="0. ë²¡í„° ì„¤ì •(ëª¨ë¸/ê²€ìƒ‰/ì²­í¬) ì—…ë°ì´íŠ¸",
)
async def update_vector_settings(body: VectorSettingsBody):
    try:
        ret = set_vector_settings(
            embed_model_key=body.embeddingModel,
            search_type=body.searchType,
            chunk_size=body.chunkSize,
            overlap=body.overlap,
        )
        return {"message": "updated", **ret}

    except Exception as e:
        # ê¸°íƒ€ ì˜¤ë¥˜ (ëª¨ë¸ íŒŒì¼ ì—†ìŒ ë“±)
        return {"error": "ë°±í„° DBì„¤ì • ë¶ˆê°€(ë°±í„° DBë¥¼ ì „ë¶€ ì‚­ì œ)", "detail": str(e)}


@router.get(
    "/admin/vector/settings",
    summary="í˜„ì¬ ë²¡í„° ì„¤ì •(ì„ë² ë”© ëª¨ë¸/ê²€ìƒ‰ ë°©ì‹) ì¡°íšŒ",
)
async def read_vector_settings():
    return get_vector_settings()


@router.get(
    "/admin/vector/embedding-models",
    summary="ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ëª¨ë¸ ëª©ë¡ ì¡°íšŒ",
)
async def list_embedding_models():
    """
    ./storage/embedding-models í´ë” ë‚´ì˜ ëª¨ë¸ í´ë”ëª…ë“¤ì„ ë°˜í™˜.
    - embedding_ ì ‘ë‘ì‚¬ê°€ ìˆìœ¼ë©´ ì œê±° (ì˜ˆ: embedding_bge_m3 â†’ bge_m3)
    """
    models = list_available_embedding_models()
    return {
        "models": models,
        "count": len(models)
    }


# ============================
# Security Levels (per task type)
# ============================

from typing import List as _ListType, Dict as _DictType
from pydantic import conint

TaskLiteral = Literal["doc_gen", "summary", "qna"]

class SecurityLevelSingleBody(BaseModel):
    maxLevel: conint(ge=1) = Field(..., description="ìµœëŒ€ ë³´ì•ˆ ë ˆë²¨(>=1)")
    levels: _DictType[str, _ListType[str] | str] = Field(default_factory=dict)

@router.post(
    "/admin/vector/security-levels/{taskType}",
    summary="1. ì‘ì—…ìœ í˜•ë³„ ë³´ì•ˆë ˆë²¨ ê·œì¹™ 'ê°œë³„' ì €ì¥(doc_gen/summary/qna ì¤‘ í•˜ë‚˜)",
    status_code=status.HTTP_200_OK,
)
async def set_security_levels_one(taskType: TaskLiteral, body: SecurityLevelSingleBody):
    try:
        res = upsert_security_level_for_task(
            task_type=taskType,
            max_level=int(body.maxLevel),
            levels_raw=body.levels,
        )
        return res
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get(
    "/admin/vector/security-levels",
    summary="ë³´ì•ˆë ˆë²¨ ê·œì¹™ ì¡°íšŒ(ì „ì²´ ë˜ëŠ” íŠ¹ì • ì‘ì—…ìœ í˜•)"
)
async def get_security_levels(taskType: Optional[TaskLiteral] = None):
    if taskType:
        return get_security_level_rules_for_task(taskType)
    return get_security_level_rules_all()


# ============================
# Pipeline
# ============================

@router.post("/admin/vector/full-ingest", summary="ì „ì²´ íŒŒì¼ ì¶”ì¶œ ë° ì €ì¥ ì¸ì œìŠ¤íŠ¸") # TODO : MinIO ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”
async def rag_full_ingest(files: List[UploadFile] = File(...)):
    # 1) RAW ì €ì¥
    rel_paths = []
    for f in files:
        rel_paths.append(save_raw_file(f.filename, folder="row_data", content=await f.read()))

    extract_result = await extract_documents(rel_paths)
    # 3) ì¸ì œìŠ¤íŠ¸
    settings = get_vector_settings()

    # 2) ì¶”ì¶œ

    ingest_result = await ingest_embeddings(
        model_key=settings["embeddingModel"],
        max_token=int(settings["chunkSize"]),
        overlab=int(settings["overlap"]),
    )
    logger.debug(f"\n\n[API] ingest_result: {ingest_result}\n\n")
    return {
        "uploaded": rel_paths,
        "extract": extract_result,
        "ingest": ingest_result,
    }


@router.post("/admin/vector/execute",summary="ê´€ë¦¬ì ê²€ìƒ‰")
async def rag_search_endpoint(body: ExecuteBody):
    print(f"ğŸ¯ [API] ê´€ë¦¬ì ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ: question='{body.question}', topK={body.topK}, rerank_topN={body.rerank_topN}")
    
    model_key = get_vector_settings()["embeddingModel"]
    print(f"ğŸ¯ [API] execute_search í˜¸ì¶œ ì‹œì‘...")
    
    result = await execute_search(
        question=body.question,
        top_k=body.topK,  # ì„ë² ë”© í›„ë³´ ê°œìˆ˜
        rerank_top_n=body.rerank_topN,  # ìµœì¢… ë°˜í™˜ ê°œìˆ˜
        security_level=body.securityLevel,
        source_filter=body.sourceFilter,
        task_type=body.taskType,
        model_key=model_key,
        search_type=body.searchMode,  # â† override
    )
    
    print(f"ğŸ¯ [API] execute_search í˜¸ì¶œ ì™„ë£Œ, ê²°ê³¼ hits={len(result.get('hits', []))}")
    return result


@router.post(
    "/user/vector/execute", summary="ì‚¬ìš©ì ê²€ìƒ‰"
)
async def user_rag_search_endpoint(body: ExecuteBody):
    model_key = get_vector_settings()["embeddingModel"]
    return await execute_search(
        question=body.question,
        top_k=body.topK,  # ì„ë² ë”© í›„ë³´ ê°œìˆ˜
        rerank_top_n=body.rerank_topN,  # ìµœì¢… ë°˜í™˜ ê°œìˆ˜
        security_level=body.securityLevel,
        source_filter=body.sourceFilter,
        task_type=body.taskType,
        model_key=model_key,
        search_type=body.searchMode,
    )


# ============================
# Management
# ============================

@router.get(
    "/admin/vector/files",
    summary="ì¸ë±ì‹±ëœ íŒŒì¼ ëª©ë¡(ì‘ì—…ìœ í˜•ë³„ ì§‘ê³„) ì¡°íšŒ"
)
async def list_vector_files_endpoint(
    limit: int = Query(1000, ge=1, le=16384),
    offset: int = Query(0, ge=0),
    q: Optional[str] = Query(None, description="íŒŒì¼ëª… ë¶€ë¶„ê²€ìƒ‰"),
    taskType: Optional[Literal["doc_gen", "summary", "qna"]] = Query(None),
):
    return await list_indexed_files(limit=limit, offset=offset, query=q, task_type=taskType)


@router.get(
    "/admin/vector/files/overview",
    summary="ì‘ì—…ìœ í˜•Â·ë³´ì•ˆë ˆë²¨ë³„ ì§‘ê³„ + íŒŒì¼ ë¦¬ìŠ¤íŠ¸"
)
async def list_vector_files_overview():
    return await list_indexed_files_overview()


@router.delete(
    "/admin/vector/delete",
    summary="íŒŒì¼ ì´ë¦„ ëª©ë¡(doc_id ìŠ¤í…œ) ê¸°ë°˜ ì‚­ì œ. taskType ì§€ì • ì‹œ í•´ë‹¹ ì‘ì—…ìœ í˜•ë§Œ ì‚­ì œ"
)
async def delete_vector_files(body: DeleteFilesBody = Body(...)):
    return await delete_files_by_names(body.filesToDelete, task_type=body.taskType)


@router.post("/admin/vector/delete", summary="[POST] íŒŒì¼ ì´ë¦„ ëª©ë¡(doc_id ìŠ¤í…œ) ê¸°ë°˜ ì‚­ì œ. taskType ì§€ì • ì‹œ í•´ë‹¹ ì‘ì—…ìœ í˜•ë§Œ ì‚­ì œ")
async def delete_vector_files_post(body: DeleteFilesBody = Body(...)):
    return await delete_files_by_names(body.filesToDelete, task_type=body.taskType)


@router.post("/admin/vector/delete-admin-collection", summary="Milvus ì„œë²„ Admin ì»¬ë ‰ì…˜ ì‚­ì œ(ì´ˆê¸°í™”)")
async def rag_delete_admin_collection_endpoint(request: Request):
    logger.debug(f"[delete-admin-collection] from {request.client.host}")
    return await delete_collection(collection_key=DocumentType.ADMIN.value)

@router.post("/admin/vector/delete-all-collections", summary="Milvus ì„œë²„ ì „ì²´ ì»¬ë ‰ì…˜ ì‚­ì œ(ì´ˆê¸°í™”)")
async def rag_delete_db_endpoint(request: Request):
    logger.debug(f"[delete-all] from {request.client.host}")
    return await delete_collection(collection_key=None)


# ì¤‘ë³µ import ì œê±° ë° ìƒë‹¨ìœ¼ë¡œ ìŠ¹ê²©ë¨

def _parse_level_for_tasks_flex(
    raw: Optional[str],
    qna_level: Optional[str] = None,
    summary_level: Optional[str] = None,
    doc_gen_level: Optional[str] = None,
) -> Dict[str, int]:
    # 1) ê°œë³„ í•„ë“œê°€ ì˜¤ë©´ ìš°ì„  ì‚¬ìš© (ë¹ˆ ë¬¸ìì—´ì€ ë¬´ì‹œ)
    def _as_int(x: Optional[str]):
        if x is None:
            return None
        s = str(x).strip()
        if s == "":
            return None
        try:
            return int(s)
        except Exception:
            return None

    lvl_map: Dict[str, int] = {}
    q = _as_int(qna_level); s = _as_int(summary_level); d = _as_int(doc_gen_level)
    if q is not None: lvl_map["qna"] = max(1, q)
    if s is not None: lvl_map["summary"] = max(1, s)
    if d is not None: lvl_map["doc_gen"] = max(1, d)
    if lvl_map:
        return lvl_map

    if raw is None or str(raw).strip() == "":
        raise ValueError("level_for_tasks ê°’ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    s = str(raw).strip()

    # 2) ìˆ«ì í•˜ë‚˜ë§Œ ì˜¤ë©´ ëª¨ë“  task ë™ì¼ ì ìš©
    if s.isdigit():
        v = max(1, int(s))
        return {"qna": v, "summary": v, "doc_gen": v}

    # 3) JSON ì‹œë„
    try:
        obj = _json.loads(s)
        if isinstance(obj, dict):
            out = {}
            for k, v in obj.items():
                if k in ("qna", "summary", "doc_gen"):
                    out[k] = max(1, int(v))
            if out:
                return out
    except Exception:
        pass

    # 4) "qna:2,summary:1" / "qna=2&summary=1" ë¥˜ íŒŒì‹±
    cand = s.replace("&", ",")
    parts = [p.strip() for p in cand.split(",") if p.strip()]
    out = {}
    for p in parts:
        if ":" in p:
            k, v = p.split(":", 1)
        elif "=" in p:
            k, v = p.split("=", 1)
        else:
            continue
        k = k.strip()
        if k in ("qna", "summary", "doc_gen"):
            try:
                out[k] = max(1, int(v))
            except Exception:
                pass
    if out:
        return out

    raise ValueError('level_for_tasks íŒŒì‹± ì‹¤íŒ¨. ì˜ˆ) {"qna":2,"summary":1} ë˜ëŠ” "qna:2,summary:1" ë˜ëŠ” "2"')
    
@router.post("/admin/vector/override-levels-upload", 
    summary="-- ë‹¨ì¼ íŒŒì¼ ì˜¬ë¦¬ê¸° "
    )
async def override_levels_upload_form(
    files: List[UploadFile] = File(...),
    tasks: Optional[str] = Form(None),
    level_for_tasks: Optional[str] = Form(None),
    qna_level: Optional[str] = Form(None),
    summary_level: Optional[str] = Form(None),
    doc_gen_level: Optional[str] = Form(None),
):
    # # 1) íŒŒì¼ ì €ì¥
    saved_original_names: List[str] = []
    saved_rel_paths : List[str] = []
    for f in files:
        # save_raw_fileì´ ìƒëŒ€ ê²½ë¡œë¥¼ ëŒë ¤ì£¼ë„ë¡ ìˆ˜ì •, 
        # ë‹¨ê±´ ì „ì²˜ë¦¬/ë“±ë¡ì„ ë‹´ë‹¹í•˜ëŠ” ìƒˆ í—¬í¼ë“¤ì„ ì¶”ê°€
        content = await f.read()
        rel_path = save_raw_file(f.filename, folder="row_data", content=content)
        saved_original_names.append(f.filename)
        saved_rel_paths.append(rel_path)

    processed_docs = await process_saved_raw_files(saved_rel_paths)
    target_tokens = [doc["doc_id"] for doc in processed_docs] or saved_original_names
    logger.debug(f"ğŸ¯ [API] target_tokens: {target_tokens}")

    # 3) task ëª©ë¡
    tlist = None
    if tasks:
        tlist = [t.strip() for t in tasks.split(",") if t.strip() in TASK_TYPES] or None

    # 4) ë ˆë²¨ íŒŒì‹±(ìœ ì—°)
    try:
        lvmap = _parse_level_for_tasks_flex(level_for_tasks, qna_level, summary_level, doc_gen_level)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

    # 5) ì§€ì • íŒŒì¼ë§Œ ë ˆë²¨ ì˜¤ë²„ë¼ì´ë“œ + í•´ë‹¹ íŒŒì¼ë§Œ ì¸ì œìŠ¤íŠ¸
    req = OverrideLevelsRequest(files=target_tokens, level_for_tasks=lvmap, tasks=tlist)
    result = await override_levels_and_ingest(req)
    return {"saved": saved_original_names, "ingest_result": result}
