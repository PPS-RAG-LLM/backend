from pydantic import BaseModel, Field
from typing import List, Optional
from fastapi import APIRouter, Depends, Path, Query, Body
from starlette.responses import StreamingResponse
from repository.workspace import get_workspace_by_workspace_id
from service.users.chat import (
    stream_chat_for_qna,
    stream_chat_for_doc_gen,
    stream_chat_for_summary,
)
from service.prompt_template.doc_gen_templates import get_doc_gen_template
from utils import logger
from errors import BadRequestError
import time, json

logger = logger(__name__)

chat_router = APIRouter(tags=["Workspace Chat"], prefix="/v1/workspace")

# ì±„íŒ…
class Attachment(BaseModel):
    name: str  # íŒŒì¼ëª…
    mime: str  # image/png, image/jpeg, application/pdf, etc.
    contentString: str  # data:image/png;base64,...


class StreamChatRequest(BaseModel):
    provider    : Optional[str] = None # ê³µê¸‰ì
    model       : Optional[str] = None # ëª¨ë¸
    message     : str # ë©”ì‹œì§€
    mode        : Optional[str] = Field(None, pattern="^(chat|query)$")
    sessionId   : Optional[str] = None # ì„¸ì…˜ ID
    attachments : List[Attachment] = Field(default_factory=list) # ì²¨ë¶€ íŒŒì¼
    reset       : Optional[bool] = False # ë¦¬ì…‹
    rag_flag    : Optional[bool] = True # RAG í”Œë˜ê·¸

@chat_router.post(
    "/{slug}/thread/{thread_slug}/stream-chat", summary="QnA ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì‹¤í–‰"
)
def stream_chat_qna_endpoint(
    category        : str = Query("qna"), # ì¹´í…Œê³ ë¦¬
    slug            : str = Path(..., description="ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ìŠ¬ëŸ¬ê·¸"),
    thread_slug     : str = Path(..., description="ì±„íŒ… ìŠ¤ë ˆë“œ ìŠ¬ëŸ¬ê·¸"),
    body            : StreamChatRequest = Body(..., description="ì±„íŒ… ìš”ì²­ ë³¸ë¬¸"),
):
    user_id         = 3
    security_level  = 2 # TODO : ìœ ì €ì •ë³´ì—ì„œ ë³´ì•ˆë ˆë²¨ ìºì‹±í•˜ì—¬ ì‚¬ìš©í•˜ê¸° (default: 2)
    logger.info(f"\n\n[stream_chat_qna_endpoint] \n{body}\n")

    gen = stream_chat_for_qna(
        user_id         = user_id,   # ì‚¬ìš©ì ID
        security_level  = security_level,         # TODO : ìœ ì €ì •ë³´ì—ì„œ ë³´ì•ˆë ˆë²¨ ìºì‹±í•˜ì—¬ ì‚¬ìš©í•˜ê¸° (default: 2)
        slug            = slug,      # ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ìŠ¬ëŸ¬ê·¸
        thread_slug     = thread_slug, # ì±„íŒ… ìŠ¤ë ˆë“œ ìŠ¬ëŸ¬ê·¸
        category        = category,  # ì¹´í…Œê³ ë¦¬
        body            = body.model_dump(exclude_unset=True), # ìš”ì²­ ë³¸ë¬¸
    )
    return StreamingResponse(to_see(gen), media_type="text/event-stream; charset=utf-8")



def to_see(gen):
    logger.info("[stream_chat_qna_endpoint] streaming start")
    buf = []
    last_flush = time.monotonic()
    chat_id = None
    full_response = []

    for chunk in gen:
        if not chunk:
            continue
        # ğŸ”¥ ì†ŒìŠ¤ ì´ë²¤íŠ¸ ê°ì§€ ë° í”„ëŸ°íŠ¸ë¡œ ì „ë‹¬
        if chunk.startswith("__SOURCES__:"):
            sources_json = chunk.split(":", 1)[1]
            yield f'{json.dumps({"sources": json.loads(sources_json)})}\n\n'
            continue
        if chunk.startswith("__CHAT_ID__:"): 
            chat_id = chunk.split(":",1)[1] # ì±„íŒ… ID ì¶”ì¶œ
            continue
        if not buf:
            chunk = chunk.lstrip()
        buf.append(chunk)
        full_response.append(chunk)
        text = "".join(buf)
        if (
            len(text) >= 32
            or text.endswith((" ","\n", ".", "?", "!", "â€¦", "ã€‚", "ï¼", "ï¼Ÿ"))
            or time.monotonic() - last_flush > 0.2
        ):
            # logger.debug(f"[flush] {repr(text)}")
            yield f'{json.dumps({"content": chunk})}\n\n'
            buf.clear()
            last_flush = time.monotonic()
    if buf:
        text = "".join(buf)
        yield f'{json.dumps({"content": chunk})}\n\n'
    if chat_id:
        yield f'{json.dumps({"chat_id": chat_id, "done":True})}\n\n'

    complete_response = "".join(full_response)
    logger.info("======================\n\n[stream_chat_qna_endpoint] streaming end - Full response "
    f"({len(complete_response)} chars): \n\n{complete_response}\n\n======================\n")


# ====== Unified POST APIs ======
class SummaryRequest(BaseModel):
    provider    : Optional[str] = None # ê³µê¸‰ì
    model       : Optional[str] = None # ëª¨ë¸
    systemPrompt: Optional[str] = None # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    originalText: Optional[str] = "ì˜¤ë¦¬ì§€ë„ í…ìŠ¤íŠ¸" # ì›ë¬¸
    userPrompt  : Optional[str] = "ìš”ì²­ì‚¬í•­" # ìš”ì²­ì‚¬í•­

@chat_router.post("/{slug}/summary/stream", summary="ë¬¸ì„œ ìš”ì•½ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)")
def summary_stream_endpoint(
    slug: str = Path(..., description="ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ìŠ¬ëŸ¬ê·¸"),
    body: SummaryRequest = Body(..., description="ìš”ì•½ ìš”ì²­ (ì‹œìŠ¤í…œí”„ë¡¬í”„íŠ¸/ë‚´ìš©/ìš”ì²­ì‚¬í•­)"),
):
    user_id = 3
    from repository.workspace import get_workspace_id_by_slug_for_user
    workspace_id = get_workspace_id_by_slug_for_user(user_id, slug)

    # Preflight ê²€ì¦
    ws = get_workspace_by_workspace_id(user_id, workspace_id)
    
    # originalTextë„ ì—†ê³  ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì— ë¬¸ì„œë„ ì—†ìœ¼ë©´ ì—ëŸ¬
    if not body.originalText:
        from repository.documents import list_workspace_documents
        workspace_docs = list_workspace_documents(workspace_id)
        if not workspace_docs:
            raise BadRequestError("ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì— ë“±ë¡ëœ ë¬¸ì„œê°€ ì—†ê³  originalTextë„ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    gen = stream_chat_for_summary(
        user_id=user_id,
        ws=ws,
        category="summary",
        body={
            "provider": body.provider,
            "model": body.model,
            "systemPrompt": body.systemPrompt,
            "originalText": body.originalText,
            "userPrompt": body.userPrompt,
        },
    )
    return StreamingResponse(to_see(gen), media_type="text/event-stream; charset=utf-8")


class VariableItem(BaseModel):
    key: str
    value: str

class DocGenRequest(BaseModel):
    provider: Optional[str] = None
    model: Optional[str] = None
    templateId: int
    systemPrompt: Optional[str] = None
    userPrompt: Optional[str] = None
    variables: List[VariableItem] = Field(default_factory=list)


@chat_router.post("/{slug}/doc-gen/stream", summary="ë¬¸ì„œ ìƒì„± ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)")
def doc_gen_stream_endpoint(
    slug: str = Path(..., description="ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ìŠ¬ëŸ¬ê·¸"),
    body: DocGenRequest = Body(..., description="ë¬¸ì„œ ìƒì„± ìš”ì²­ (í…œí”Œë¦¿/ë³€ìˆ˜/ìš”ì²­ì‚¬í•­)"),
):
    from repository.workspace import get_workspace_id_by_slug_for_user
    user_id = 3
    tmpl = get_doc_gen_template(int(body.templateId))
    if not tmpl:
        raise BadRequestError("ìœ íš¨í•˜ì§€ ì•Šì€ templateId ì…ë‹ˆë‹¤.")
    allowed_keys = {str(v.get("key") or "") for v in (tmpl.get("variables") or []) if v.get("key")}
    variables = [(item.key.strip(), item.value) for item in (body.variables or []) if (item.key or "").strip()]
    provided_keys = {key for key, _ in variables}
    missing = {key for key in allowed_keys if key and key not in provided_keys}
    if missing:
        raise BadRequestError(f"í•„ìˆ˜ ë³€ìˆ˜ ëˆ„ë½: {sorted(missing)}")
    filtered_vars = {key: value for key, value in variables if key in allowed_keys}
    logger.debug(f"\nallowed_keys: {allowed_keys}\nprovided_keys: {provided_keys}\nmissing: {missing}\nfiltered_vars: {filtered_vars}\nvariables: {variables}")

    workspace_id = get_workspace_id_by_slug_for_user(user_id, slug)

    # Preflight ê²€ì¦
    ws = get_workspace_by_workspace_id(user_id, workspace_id)
    
    message = (body.userPrompt or "").strip() or "ìš”ì²­ëœ í…œí”Œë¦¿ì— ë”°ë¼ ë¬¸ì„œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”."
    gen = stream_chat_for_doc_gen(
        user_id=user_id,
        ws=ws,
        category="doc_gen",
        body={
            "provider": body.provider,
            "model": body.model,
            "message": message,
            "mode": "chat",
            "systemPrompt": body.systemPrompt,
            "templateId": body.templateId,
            "templateVariables": filtered_vars,
        },
    )
    return StreamingResponse(to_see(gen), media_type="text/event-stream; charset=utf-8")


class UpdateMetricsRequest(BaseModel):
    reasoningDuration: float = Field(..., description="ì¶”ë¡  ì‹œê°„ (ì´ˆ)", ge=0)

@chat_router.patch(
    "/{slug}/chat/{chat_id}/metrics",
    summary="ì±„íŒ… ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸",
    description="í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ê³„ì‚°í•œ reasoning_durationì„ ì—…ë°ì´íŠ¸"
)
def update_chat_metrics_endpoint(
    chat_id: int = Path(..., description="ì±„íŒ… ID"),
    body: UpdateMetricsRequest = Body(..., description="ì±„íŒ… ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ìš”ì²­"),
):
    """
    í”„ë¡ íŠ¸ì—”ë“œê°€ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¤‘ ê³„ì‚°í•œ reasoning_durationì„ ì €ì¥
    """
    from service.users.chat.response_metrics import update_reasoning_duration
    user_id = 3
    result = update_reasoning_duration(user_id, chat_id, body.reasoningDuration)
    return {"success": True, "data": result}