
```
ssh -L 3007:localhost:3007 KT-Cloud

Funk-Enduring-Brutus-Thud-Absolument-Jeg

cd /home/work/CoreIQ/backend
conda activate backend
uvicorn main:app --host 0.0.0.0 --port 3007 --reload

http://localhost:3007/docs

== 처음 설치 시 == 
conda create --name backend python=3.11
conda activate backend
pip install fastapi \
            streamlit \
            pymupdf \
            frontend \
            sentence_transformers\
            pandas\
            pyarrow\
            dill\
            aiohttp\
            numpy\
            accelerate\
            chardet\
            dotenv\
            bcrypt\
            pymilvus


pip install peft bitsandbytes accelerate
            
--upgrade --force-reinstall sentence-transformers


==
conda activate coreIQ


-test
# 보안 레벨 설정
{
  "maxLevel": 3,
  "levels": {
    "2": "@연구@윤리@연봉",
    "3": "@부정청탁@퇴직금"
  }
}
# 폴더명
/home/work/CoreIQ/backend/storage/user_data/local_data
# 중복 테스트
/home/work/CoreIQ/backend/storage/user_data/local_data/securityLevel3/81._부정청탁및금품등수수의신고사무처리에관한내규_20191128.pdf

# 리트리버
부정청탁에 관련된 내용을 알려줘




```




```
== 백터 DB 관련 == 
https://huggingface.co/spaces/mteb/leaderboard
여기서 0.6b 임베딩 모델로 변경

docker로 변경해서 작업해야 함.

sql 연결 다 잘 되었는지 확인해야 함. 

== 모델 학습 시 == 파인튜닝 관련
QLORA, LORA, FULL
{
  "baseModelName": "Qwen2.5-7B-Instruct-1M",
  "saveModelName": "Qwen2.5-7B-Instruct-1M-20250822",
  "systemPrompt": "위 내용을 참고하여 응답해 주세요.",
  "batchSize": 4,
  "epochs": 3,
  "learningRate": 0.0002,
  "overfittingPrevention": true,
  "trainSetFile": "data.csv",
  "gradientAccumulationSteps": 8,
  "tuningType": "QLORA"
}
python /home/work/CoreIQ/backend/storage/db_del.py


```


```

oss 관련 
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

pip uninstall -y torch bitsandbytes
```

```
모델 관리 관련


# api # v1/admin/llm/model/download # 한개의 모델만 추가 


{
  "name": "Qwen2.5-7B-Instruct-1M",
  "model_path": "Qwen2.5-7B-Instruct-1M",
  "provider": "huggingface",
  "tags": [
    "all"
  ]
}

=> 이렇게 하면 

문제 oss 


```