{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# db Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3, pathlib\n",
    "\n",
    "path = \"/home/work/CoreIQ/Ruah/backend/storage/pps_rag.db\"\n",
    "schema_path = \"/home/work/CoreIQ/Ruah/backend/storage/schema.sql\"\n",
    "\n",
    "sql = pathlib.Path(schema_path).read_text(encoding=\"utf-8\")\n",
    "con = sqlite3.connect(path)\n",
    "con.execute(\"PRAGMA foreign_keys=ON;\")\n",
    "con.executescript(sql)\n",
    "con.commit()\n",
    "con.close()\n",
    "\n",
    "\n",
    "def get_db():\n",
    "    conn = sqlite3.connect(path)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import hashlib\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def hash_password(plain_password: str) -> str:\n",
    "    \"\"\"Return a SHA-256 hex digest for the given plain password.\n",
    "    Consider switching to bcrypt/argon2 in production environments.\n",
    "    \"\"\"\n",
    "    return hashlib.sha256(plain_password.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def create_user(\n",
    "    username: str,\n",
    "    name: str,\n",
    "    password: str,\n",
    "    department: str,\n",
    "    position: str,\n",
    "    role: str = \"user\",\n",
    "    pfp_filename: Optional[str] = None,\n",
    "    bio: str = \"\",\n",
    "    daily_message_limit: Optional[int] = None,\n",
    "    suspended: int = 0,\n",
    "    security_level: int = 3,\n",
    ") -> int:\n",
    "    \"\"\"Insert a new user row into the users table and return the inserted row id.\n",
    "\n",
    "    Required: username, name, password, department, position\n",
    "    Optional: role, pfp_filename, bio, daily_message_limit, suspended, security_level\n",
    "    \"\"\"\n",
    "    hashed = hash_password(password)\n",
    "\n",
    "    conn = get_db()\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO users (\n",
    "                role, username, name, password, department, position,\n",
    "                pfp_filename, bio, daily_message_limit, suspended, security_level\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\",\n",
    "            (\n",
    "                role,\n",
    "                username,\n",
    "                name,\n",
    "                hashed,\n",
    "                department,\n",
    "                position,\n",
    "                pfp_filename,\n",
    "                bio,\n",
    "                daily_message_limit,\n",
    "                suspended,\n",
    "                security_level,\n",
    "            ),\n",
    "        )\n",
    "        conn.commit()\n",
    "        return cursor.lastrowid\n",
    "    except sqlite3.IntegrityError as exc:\n",
    "        # Likely a UNIQUE constraint failure on username\n",
    "        raise ValueError(f\"Failed to create user: {exc}\") from exc\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted user id: 3\n"
     ]
    }
   ],
   "source": [
    "# 사용 예시 (필요 시 값 변경 후 실행)\n",
    "new_user_id = create_user(\n",
    "    role=\"user\",\n",
    "    username=\"gijung123\",\n",
    "    name=\"조기정\",\n",
    "    password=\"1234\",\n",
    "    department=\"AI 연구소\",\n",
    "    position=\"선임연구원\",\n",
    "    security_level=2,\n",
    ")\n",
    "print(\"inserted user id:\", new_user_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_user_by_id(user_id: int) -> int:\n",
    "    \"\"\"\n",
    "    users 테이블에서 해당 ID 삭제.\n",
    "    관련 user_sessions도 함께 삭제.\n",
    "    반환: 삭제된 사용자 개수(0 또는 1)\n",
    "    \"\"\"\n",
    "    conn = get_db()\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        # 매핑 먼저 정리\n",
    "        cur.execute(\"DELETE FROM user_sessions WHERE user_id = ?\", (user_id,))\n",
    "        # 사용자 삭제\n",
    "        cur.execute(\"DELETE FROM users WHERE id = ?\", (user_id,))\n",
    "        deleted = cur.rowcount\n",
    "        conn.commit()\n",
    "        return deleted\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_user_by_id(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System prompt\n",
    "## create prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "def create_system_prompt_template(\n",
    "    name: str,\n",
    "    category: str,       # \"qa\" | \"doc_gen\" | \"summary\"\n",
    "    content: str,\n",
    "    required_vars: Optional[List[str]] = None,   # [\"document_title\",\"author\"] 등\n",
    "    is_default: bool = False,\n",
    "    is_active: bool = True,\n",
    "    variable_specs: Optional[List[Dict[str, Any]]] = None,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    system_prompt_template를 생성합니다.\n",
    "    - category가 'doc_gen'이면 변수(system_prompt_variables)와 매핑(prompt_mapping)도 함께 생성합니다.\n",
    "    - variable_specs 형식 예:\n",
    "      [\n",
    "        {\"type\": \"text\", \"key\": \"제목\", \"value\": None, \"description\": \"예: 일본 출장 계획서\"},\n",
    "        {\"type\": \"datetime\", \"key\": \"마감일\", \"description\": \"예: 2025-08-12\"},\n",
    "      ]\n",
    "    - variable_specs가 없고 required_vars만 전달되면, doc_gen의 경우 'text' 타입으로 자동 생성합니다.\n",
    "    \"\"\"\n",
    "    # doc_gen 변수 이름 목록 결정\n",
    "    if category == \"doc_gen\":\n",
    "        if not variable_specs and not required_vars:\n",
    "            raise ValueError(\"doc_gen 카테고리는 variable_specs 또는 required_vars가 필요합니다.\")\n",
    "        if not variable_specs and required_vars:\n",
    "            # required_vars만 있으면 text 타입으로 자동 구성\n",
    "            variable_specs = [{\"type\": \"text\", \"key\": k} for k in required_vars]\n",
    "        var_names = [v[\"key\"] for v in variable_specs]  # 템플릿 required_vars에 저장될 키 목록\n",
    "    else:\n",
    "        var_names = required_vars or []\n",
    "\n",
    "    conn = get_db()\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # 1) 템플릿 생성\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO system_prompt_template\n",
    "              (name, category, content, required_vars, is_default, is_active)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "            \"\"\",\n",
    "            (\n",
    "                name,\n",
    "                category,\n",
    "                content,\n",
    "                json.dumps(var_names, ensure_ascii=False),\n",
    "                1 if is_default else 0,\n",
    "                1 if is_active else 0,\n",
    "            ),\n",
    "        )\n",
    "        template_id = cur.lastrowid\n",
    "\n",
    "        # 2) doc_gen이면 변수/매핑 생성\n",
    "        if category == \"doc_gen\":\n",
    "            # 변수 생성\n",
    "            var_ids: List[int] = []\n",
    "            for spec in variable_specs or []:\n",
    "                vtype = spec.get(\"type\", \"text\")\n",
    "                key = spec[\"key\"]\n",
    "                value = spec.get(\"value\")\n",
    "                description = spec.get(\"description\", \"\")\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO system_prompt_variables (type, key, value, description)\n",
    "                    VALUES (?, ?, ?, ?)\n",
    "                    \"\"\",\n",
    "                    (vtype, key, value, description),\n",
    "                )\n",
    "                var_ids.append(cur.lastrowid)\n",
    "\n",
    "            # 매핑 생성\n",
    "            for vid in var_ids:\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO prompt_mapping (template_id, variable_id)\n",
    "                    VALUES (?, ?)\n",
    "                    \"\"\",\n",
    "                    (template_id, vid),\n",
    "                )\n",
    "\n",
    "        conn.commit()\n",
    "        return template_id\n",
    "    except Exception:\n",
    "        conn.rollback()\n",
    "        raise\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid = create_system_prompt_template(\n",
    "    name=\"채용 공고\",\n",
    "    category=\"doc_gen\",\n",
    "    content=\"\"\"\n",
    "당신은 채용 공고 문서를 작성하는 AI 어시스턴트입니다.  \n",
    "아래 제공된 변수 값을 참고하여 회사와 채용 포지션 정보를 명확하고 매력적으로 문서 형식으로 작성하세요.\n",
    "\n",
    "작성 규칙:\n",
    "1. 문서는 직무명, 회사 소개, 담당 업무, 자격 요건, 우대 사항, 근무 조건, 지원 방법 순으로 구성\n",
    "2. 중요 정보가 돋보이도록 불릿 포인트와 명확한 문장 사용\n",
    "3. 불필요한 수식어나 반복 표현은 제거하며, 지원자 입장에서 이해하기 쉽게 작성\n",
    "4. 제공된 변수들을 자연스럽게 연결하여 문장 작성\n",
    "5. 날짜는 YYYY-MM-DD 형식으로 표기\n",
    "\"\"\",\n",
    "    is_default=True,\n",
    "    variable_specs=[\n",
    "        {\"type\": \"text\", \"key\": \"직무명\", \"description\": \"채용하는 직무명 (예: 소프트웨어 엔지니어)\"},\n",
    "        {\"type\": \"text\", \"key\": \"회사소개\", \"description\": \"회사 개요 및 비전 소개\"},\n",
    "        {\"type\": \"text\", \"key\": \"담당업무\", \"description\": \"직무별 주요 업무 내용\"},\n",
    "        {\"type\": \"text\", \"key\": \"자격요건\", \"description\": \"필수 자격 및 능력 조건\"},\n",
    "        {\"type\": \"text\", \"key\": \"우대사항\", \"description\": \"우대하는 경험이나 기술 (선택 사항)\"},\n",
    "        {\"type\": \"text\", \"key\": \"근무조건\", \"description\": \"근무지, 근무 형태, 근무 시간 등 근무 관련 사항\"},\n",
    "        {\"type\": \"datetime\", \"key\": \"지원마감일\", \"description\": \"채용 지원 마감일\"},\n",
    "        {\"type\": \"text\", \"key\": \"지원방법\", \"description\": \"지원 절차나 연락처 등 안내\"}\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시:\n",
    "tid = create_system_prompt_template(\n",
    "    name=\"기본 QA Prompt\",\n",
    "    category=\"qa\",\n",
    "    content=\"\"\"당신은 친절하고 이해하기 쉬운 설명을 제공하는 AI 어시스턴트입니다.\n",
    "사용자의 질문이나 요청에 대해 정확하고 간결하게, 그리고 가능하다면 추가적인 배경 지식과 예시를 곁들여 답변하세요.\n",
    "어려운 용어나 개념이 나올 경우, 초보자도 이해할 수 있도록 쉽게 풀어 설명하고, 필요하다면 목록·표·코드 블록 등을 활용하세요.\n",
    "대화는 항상 존중과 긍정적인 어조를 유지하며, 사용자의 의도와 목표를 먼저 확인한 뒤에 답변을 구성합니다.\n",
    "\n",
    "응답 스타일 가이드:\n",
    "\n",
    "핵심 정보 먼저 제시\n",
    "\n",
    "불필요하게 긴 문장 대신 명확한 구조\n",
    "\n",
    "예시, 정의, 비교 설명 활용\n",
    "\n",
    "질문이 모호하면 추가 질문으로 의도 명확히 하기\n",
    "\n",
    "사용자가 원할 경우 심화 정보 제공\"\"\",\n",
    "    required_vars=None,\n",
    "    is_default=True,\n",
    "    is_active=True,\n",
    ")\n",
    "print(\"inserted template id:\", tid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def delete_system_prompt_template_by_id(template_id: int) -> int:\n",
    "    \"\"\"\n",
    "    system_prompt_template에서 해당 ID 삭제.\n",
    "    관련 prompt_mapping도 함께 삭제.\n",
    "    반환: 삭제된 템플릿 개수(0 또는 1)\n",
    "    \"\"\"\n",
    "    conn = get_db()\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        # 매핑 먼저 정리\n",
    "        cur.execute(\"DELETE FROM prompt_mapping WHERE template_id = ?\", (template_id,))\n",
    "        # 템플릿 삭제\n",
    "        cur.execute(\"DELETE FROM system_prompt_template WHERE id = ?\", (template_id,))\n",
    "        deleted = cur.rowcount\n",
    "        conn.commit()\n",
    "        return deleted\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_system_prompt_template_by_id(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save LLM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from typing import Optional\n",
    "\n",
    "def create_llm_model(\n",
    "    provider: str,\n",
    "    name: str,\n",
    "    category: str,        # \"qa\" | \"doc_gen\" | \"summary\"\n",
    "    type_: str = \"base\",  # \"base\" | \"lora\" | \"full\"\n",
    "    revision: Optional[int] = None,\n",
    "    model_path: Optional[str] = None,\n",
    "    is_default: bool = False,\n",
    "    is_active: bool = True,\n",
    "    trained_at: Optional[str] = None,  # \"YYYY-MM-DD HH:MM:SS\" 또는 None\n",
    ") -> int:\n",
    "    if category not in (\"qa\", \"doc_gen\", \"summary\"):\n",
    "        raise ValueError(\"category must be one of: qa, doc_gen, summary\")\n",
    "    if type_ not in (\"base\", \"lora\", \"full\"):\n",
    "        raise ValueError(\"type must be one of: base, lora, full\")\n",
    "\n",
    "    conn = get_db()\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO llm_models\n",
    "              (provider, name, revision, model_path, category, type, is_default, is_active, trained_at)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\",\n",
    "            (\n",
    "                provider,\n",
    "                name,\n",
    "                revision,\n",
    "                model_path,\n",
    "                category,\n",
    "                type_,\n",
    "                1 if is_default else 0,\n",
    "                1 if is_active else 0,\n",
    "                trained_at,\n",
    "            ),\n",
    "        )\n",
    "        conn.commit()\n",
    "        return cur.lastrowid\n",
    "    except sqlite3.IntegrityError as e:\n",
    "        # name은 UNIQUE, 카테고리별 is_default=1은 트리거+부분 유니크 인덱스\n",
    "        raise ValueError(f\"Failed to create llm_model: {e}\") from e\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted model id: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/work/CoreIQ/gpu_use/KT_sever/local_gpt_oss_20b'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용 예시:\n",
    "mid = create_llm_model(\n",
    "    provider=\"huggingface\",\n",
    "    name=\"gpt_oss_20b_doc_gen\",\n",
    "    category=\"doc_gen\",\n",
    "    type_=\"base\",\n",
    "    model_path=\"/home/work/CoreIQ/gpu_use/KT_sever/local_gpt_oss_20b\",\n",
    "    is_active=True,\n",
    "    is_default=True,   # 같은 카테고리 기존 기본값은 자동 해제됨\n",
    ")\n",
    "print(\"inserted model id:\", mid)\n",
    "\n",
    "\n",
    "\"/home/work/CoreIQ/gpu_use/KT_sever/local_Qwen2.5-VL-7B-Instruct\"\n",
    "\"/home/work/CoreIQ/gpu_use/KT_sever/local_Qwen2.5-7B-Instruct\"\n",
    "\"/home/work/CoreIQ/gpu_use/KT_sever/local_gpt_oss_20b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Default LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default_llm_model(name: str, category: str ) -> bool:\n",
    "    \"\"\"\n",
    "    - name으로 대상 모델 조회\n",
    "    - (옵션) category가 주어지면 대상 모델의 category와 일치 검증\n",
    "    - 같은 category에서 대상만 is_default=1, 나머지는 0으로 원샷 토글\n",
    "    - 비활성(is_active=0) 모델은 기본값 불가\n",
    "    \"\"\"\n",
    "    con = get_db()\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"SELECT id, category, is_active FROM llm_models WHERE name=?\", (name,))\n",
    "        row = cur.fetchone()\n",
    "        print(row)\n",
    "        if not row:\n",
    "            print(f\"[WARN] LLM model not found: name={name}\")\n",
    "            return False\n",
    "\n",
    "        model_id = row[\"id\"]\n",
    "        model_category = row[\"category\"]\n",
    "        is_active = bool(row[\"is_active\"])\n",
    "\n",
    "        if category and category != model_category:\n",
    "            raise ValueError(f\"category mismatch: expected '{category}', got '{model_category}' for model '{name}'\")\n",
    "        if not is_active:\n",
    "            raise ValueError(f\"cannot set inactive model as default: name={name}\")\n",
    "\n",
    "        # 같은 카테고리에서 대상만 1, 나머지는 0\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            UPDATE llm_models\n",
    "            SET is_default = CASE WHEN id = ? THEN 1 ELSE 0 END\n",
    "            WHERE category = ?\n",
    "            \"\"\",\n",
    "            (model_id, model_category),\n",
    "        )\n",
    "        con.commit()\n",
    "        print(f\"[OK] Default LLM set: category={model_category}, name={name}\")\n",
    "        return cur.rowcount > 0\n",
    "    except sqlite3.IntegrityError as e:\n",
    "        con.rollback()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlite3.Row object at 0x7fbc7c43f4c0>\n",
      "[OK] Default LLM set: category=qa, name=qwen_2.5_7b_instruct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_default_llm_model(\"qwen_2.5_7b_instruct\", category=\"qa\")\n",
    "#set_default_llm_model(\"gpt_oss_20b\", category=\"qa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_llm_models(category: str):\n",
    "    \"\"\"\n",
    "    카테고리별 모델/기본값 상태 확인용\n",
    "    \"\"\"\n",
    "    con = get_db()\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        if category:\n",
    "            cur.execute(\n",
    "                \"SELECT id, provider, name, category, is_default, is_active FROM llm_models WHERE category=? ORDER BY id\",\n",
    "                (category,),\n",
    "            )\n",
    "        else:\n",
    "            cur.execute(\n",
    "                \"SELECT id, provider, name, category, is_default, is_active FROM llm_models ORDER BY category, id\"\n",
    "            )\n",
    "        rows = cur.fetchall()\n",
    "        for r in rows:\n",
    "            print(f\"{r['id']:>3} | {r['category']:<8} | {r['provider']:<11} | {r['name']:<24} | default={r['is_default']} | active={r['is_active']}\")\n",
    "        return rows\n",
    "    finally:\n",
    "        con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1 | qa       | huggingface | qwen-2.5-vl-7b-instruct  | default=0 | active=1\n",
      "  2 | qa       | huggingface | qwen-2.5-7b-instruct     | default=1 | active=1\n",
      "  3 | qa       | huggingface | gpt_oss_20b              | default=0 | active=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<sqlite3.Row at 0x7f2c6f7c36d0>,\n",
       " <sqlite3.Row at 0x7f2c6f7c1b10>,\n",
       " <sqlite3.Row at 0x7f2c6f7c3e50>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_llm_models(\"qa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db exists: True\n",
      "rows: 3\n",
      "1 huggingface 'qwen-2.5-vl-7b-instruct' 23 7177656E2D322E352D766C2D37622D696E737472756374\n",
      "2 huggingface 'qwen-2.5-7b-instruct' 20 7177656E2D322E352D37622D696E737472756374\n",
      "3 huggingface 'gpt_oss_20b' 11 6770745F6F73735F323062\n",
      "target: 'gpt-oss-20b' 11 6770742d6f73732d323062\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import sqlite3, os\n",
    "\n",
    "DB = \"/home/work/CoreIQ-RA/backend/storage/pps_rag.db\"\n",
    "con = sqlite3.connect(DB); con.row_factory = sqlite3.Row\n",
    "cur = con.cursor()\n",
    "\n",
    "print(\"db exists:\", os.path.exists(DB))\n",
    "print(\"rows:\", cur.execute(\"SELECT COUNT(*) FROM llm_models\").fetchone()[0])\n",
    "\n",
    "for r in cur.execute(\"SELECT id, provider, name, length(name) AS L, hex(name) AS HX FROM llm_models\"):\n",
    "    print(r[\"id\"], r[\"provider\"], repr(r[\"name\"]), r[\"L\"], r[\"HX\"])\n",
    "\n",
    "target = \"gpt-oss-20b\"  # 실제 찾을 이름\n",
    "print(\"target:\", repr(target), len(target), target.encode().hex())\n",
    "\n",
    "print(cur.execute(\"SELECT id,name FROM llm_models WHERE name = ?\", (target,)).fetchone())\n",
    "print(cur.execute(\"SELECT id,name FROM llm_models WHERE TRIM(name)=TRIM(?)\", (target,)).fetchone())\n",
    "print(cur.execute(\"SELECT id,name FROM llm_models WHERE name = ? COLLATE NOCASE\", (target,)).fetchone())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coreIQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
