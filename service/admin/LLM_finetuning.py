# service/admin/LLM_finetuning.py
from __future__ import annotations

# UnslothÎäî ÌïÑÏöîÏãúÏóêÎßå MXFP4 Î∂ÑÍ∏∞ÏóêÏÑú import (Gemma Ìå®Ïπò Ï∂©Îèå Î∞©ÏßÄ)

import os
import re
from urllib.parse import quote_plus
# üîß CUDA Î©îÎ™®Î¶¨ Îã®Ìé∏Ìôî ÏôÑÌôî (Í∂åÏû•)
os.environ.setdefault("PYTORCH_CUDA_ALLOC_CONF", "max_split_size_mb:512,expandable_segments:True,roundup_power2_divisions:16")

import json
import threading
import time
import uuid
import tempfile
import shutil
from dataclasses import dataclass
from datetime import datetime, timezone, timedelta
from typing import Any, Dict, Optional
from pathlib import Path

from pydantic import BaseModel, Field, field_validator, model_validator
from utils import logger
from errors.exceptions import BadRequestError, InternalServerError, NotFoundError
from config import config as app_config

# --- Repository Imports ---
from repository.llm_finetuning import update_job_status, finish_job_success, fail_job
from utils.database import get_session

logger = logger(__name__)


# ===== ÎîîÎ∞îÏù¥Ïä§ Ïú†Ìã∏ =====
def _get_model_device(model):
    try:
        return model.get_input_embeddings().weight.device
    except Exception:
        pass
    try:
        return next(model.parameters()).device
    except Exception:
        pass
    import torch as _torch
    return _torch.device("cuda" if _torch.cuda.is_available() else "cpu")


# ===== Config.yaml Í∏∞Î∞ò ÏÑ§Ï†ï Î°úÎìú =====
ft_conf = app_config.get("fine_tuning")
if not ft_conf:
    raise ValueError("config.yaml: 'fine_tuning' section is required")

FT_PROGRESS_INTERVAL_SEC = ft_conf.get("progress_interval_sec", 2)
FT_HEARTBEAT_TIMEOUT_SEC = ft_conf.get("heartbeat_timeout_sec", 300)
MAX_OOM_RETRIES = ft_conf.get("max_oom_retries", 1)

# ===== Paths =====
# BASE_BACKEND Í≥ÑÏÇ∞: Ïù¥ ÌååÏùºÏùò ÏÉÅÏúÑ 3Îã®Í≥Ñ(service/admin/ -> service/ -> backend/)
BASE_BACKEND = Path(__file__).resolve().parents[2]

# Î™®Îç∏ Í≤ΩÎ°ú (ÌïÑÏàò)
LLM_MODELS_ROOT = app_config.get("models_dir", {}).get("llm_models_path")
STORAGE_MODEL_ROOT = str(BASE_BACKEND / LLM_MODELS_ROOT)

# ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú (ÌïÑÏàò)
_TRAIN_DATA_REL = ft_conf.get("train_data_dir")
TRAIN_DATA_ROOT = str(BASE_BACKEND / _TRAIN_DATA_REL)


# ===== SQLAlchemy ORM (Session) =====
from sqlalchemy import create_engine, select, func
from sqlalchemy.orm import sessionmaker
from storage.db_models import (
    LlmModel, FineTuneDataset, FineTuneJob as ORMJob, FineTunedModel
)

# DB_URL Ï†úÍ±∞ Î∞è get_session ÏÇ¨Ïö©ÏúºÎ°ú ÎåÄÏ≤¥Îê®

# ---- Portable path helper ----
def _to_rel(p: str) -> str:
    """Return `p` as a path **relative** to the backend root so DB records do
    not depend on absolute host paths (useful inside Docker). If conversion
    fails, the original path is returned unchanged."""
    try:
        return os.path.relpath(p, BASE_BACKEND)
    except Exception:
        return p

def _to_service_rel(p: str) -> str:
    """
    Ïñ¥Îñ§ Í≤ΩÎ°úÎì† ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú './service/<...>' ÌòïÌÉúÎ°ú ÌëúÏ§ÄÌôî.
    Ïòà) /.../backend/storage/models/llm/Qwen3-8B  ‚Üí ./service/storage/models/llm/Qwen3-8B
        storage/models/llm/Qwen3-8B               ‚Üí ./service/storage/models/llm/Qwen3-8B
        ./service/storage/models/llm/Qwen3-8B     ‚Üí Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ
    """
    # Ï†àÎåÄÍ≤ΩÎ°úÎ©¥ backend Í∏∞Ï§Ä ÏÉÅÎåÄÍ≤ΩÎ°úÎ°ú
    if os.path.isabs(p):
        p = os.path.relpath(p, BASE_BACKEND)
    s = p.replace("\\", "/").lstrip("./")
    if not s.startswith("service/"):
        s = f"service/{s}"
    # Ï§ëÎ≥µ Ïä¨ÎûòÏãú Ï†ïÎ¶¨
    while "//" in s:
        s = s.replace("//", "/")
    return f"./{s}"

# ===== Helpers: path resolve =====
def _resolve_model_dir(name_or_path: str) -> str:
    """Resolve a local model directory for finetuning.
    Priority: DB.llm_models.model_path (by exact name, then base-name) ‚Üí STORAGE_MODEL_ROOT/name.
    Ïù∏ÌÑ∞ÎÑ∑ Îã§Ïö¥Î°úÎìúÎäî ÏãúÎèÑÌïòÏßÄ ÏïäÏùå.
    """
    if os.path.isabs(name_or_path):
        return name_or_path
    
    # 1) DBÏóêÏÑú llm_models ÌÖåÏù¥Î∏î Ï°∞Ìöå
    try:
        with get_session() as s:
            # Ï†ïÌôïÌïú Ïù¥Î¶ÑÏúºÎ°ú Î®ºÏ†Ä Ï∞æÍ∏∞
            stmt = select(LlmModel).where(LlmModel.name == name_or_path)
            model = s.execute(stmt).scalars().first()

            if not model:
                # Ïπ¥ÌÖåÍ≥†Î¶¨ Ï†ëÎØ∏ÏÇ¨ Ï†úÍ±∞ ÌõÑ Îã§Ïãú Ï∞æÍ∏∞
                def _strip_cat(n: str) -> str:
                    for suf in ("-qa", "-doc_gen", "-summary"):
                        if n.endswith(suf):
                            return n[: -len(suf)]
                    return n
                
                base_name = _strip_cat(name_or_path)
                if base_name != name_or_path:
                    stmt = select(LlmModel).where(LlmModel.name == base_name)
                    model = s.execute(stmt).scalars().first()

            if model and model.model_path:
                p = model.model_path
                if os.path.isabs(p):
                    return p
                # ÏÉÅÎåÄ Í≤ΩÎ°úÏù∏ Í≤ΩÏö∞ STORAGE_MODEL_ROOT Í∏∞Ï§ÄÏúºÎ°ú Ìï¥ÏÑù
                cand = os.path.join(STORAGE_MODEL_ROOT, p)
                if os.path.isdir(cand):
                    return cand
    except Exception as e:
        logger.warning(f"DB lookup failed for model {name_or_path}: {e}")
    
    # 2) Fallback to storage root
    return os.path.join(STORAGE_MODEL_ROOT, name_or_path)

def _has_model_signature(dir_path: str) -> bool:
    if not os.path.isdir(dir_path):
        return False
    sigs = [
        "config.json",
        "model.safetensors",
        "pytorch_model.bin",
        "generation_config.json",
    ]
    return any(os.path.isfile(os.path.join(dir_path, s)) for s in sigs)

def _resolve_train_path(p: str) -> str:
    if os.path.isabs(p):
        return p
    cand = os.path.join(TRAIN_DATA_ROOT, p)
    if os.path.isfile(cand):
        return cand
    try:
        for root, _, files in os.walk(TRAIN_DATA_ROOT):
            if p in files:
                return os.path.join(root, p)
    except Exception:
        pass
    return os.path.abspath(p)

# ===== Helpers: detect MXFP4 / gpt-oss =====
def _looks_like_mxfp4_model(dir_or_name: str) -> bool:
    name = (dir_or_name or "").lower()
    if "gpt-oss" in name:
        return True
    # Î°úÏª¨ Ìè¥ÎçîÏùº Í≤ΩÏö∞ configÏóêÏÑú ÌûåÌä∏ Ï∞æÍ∏∞
    try:
        cand = os.path.join(dir_or_name, "config.json")
        if os.path.isfile(cand):
            with open(cand, "r", encoding="utf-8") as f:
                cfg = json.load(f)
            txt = json.dumps(cfg).lower()
            if "mxfp4" in txt or "mx" in txt:
                return True
    except Exception:
        pass
    # ÏñëÏûêÌôî ÏÑ§Ï†ï ÌååÏùº ÏºÄÏù¥Ïä§
    for q in ("quantization_config.json", "quantize_config.json"):
        try:
            cand = os.path.join(dir_or_name, q)
            if os.path.isfile(cand):
                with open(cand, "r", encoding="utf-8") as f:
                    if "mxfp4" in f.read().lower():
                        return True
        except Exception:
            pass
    return False

# ===== Schemas =====
class FineTuneRequest(BaseModel):
    # === Í≥µÌÜµ ÌÉúÍ∑∏(ÌïÑÏàò) ===
    category: str = Field(..., description="qa | doc_gen | summary")
    subcategory: Optional[str] = Field(None, description="ÏÑ∏Î∂Ä ÌÖåÏä§ÌÅ¨. ÌòÑÏû¨ Ï£ºÎ°ú doc_genÏóêÏÑú ÏÇ¨Ïö©")

    baseModelName: str
    saveModelName: str
    systemPrompt: str
    batchSize: int = 1
    epochs: int = 3
    learningRate: float = 2e-4
    overfittingPrevention: bool = True
    trainSetFile: str
    gradientAccumulationSteps: int = 16
    quantizationBits: Optional[int] = Field(
        default=None, description="QLORA Ï†ÑÏö©: ÏñëÏûêÌôî ÎπÑÌä∏ (4 ÎòêÎäî 8)",
    )
    tuningType: Optional[str] = Field(
        default="QLORA",
        description="ÌååÏù∏ÌäúÎãù Î∞©Ïãù: LORA | QLORA | FULL",
        pattern="^(LORA|QLORA|FULL)$",
    )
    startAt: Optional[str] = Field(
        default=None, description="ÏòàÏïΩ ÏãúÏûë ISO8601 (Ïòà: 2025-09-19T13:00:00)"
    )
    startNow: bool = Field(
        default=False, description="Ï¶âÏãú Ïã§Ìñâ Ïó¨Î∂Ä (True: Î∞îÎ°ú ÏãúÏûë, False: ÏòàÏïΩÎßå Îì±Î°ù)"
    )

    @field_validator("category")
    @classmethod
    def _v_category(cls, v: str) -> str:
        allowed = {"qa", "doc_gen", "summary"}
        vv = (v or "").strip().lower()
        if vv not in allowed:
            raise ValueError(f"category must be one of {sorted(allowed)}")
        return vv

    @field_validator("quantizationBits")
    @classmethod
    def _v_qbits_range(cls, v: Optional[int]):
        if v is None:
            return v
        if v not in (4, 8):
            raise ValueError("quantizationBits must be 4 or 8 when provided")
        return v

    @model_validator(mode="after")
    def _v_qbits_required_for_qlora(self):
        if (self.tuningType or "").upper() == "QLORA":
            if self.quantizationBits not in (4, 8):
                raise ValueError("QLORA requires quantizationBits=4 or 8")
        return self

@dataclass
class FineTuneJob:
    job_id: str
    category: str
    request: Dict[str, Any]
    status: str = "queued"  # queued | running | succeeded | failed

# ===== Common utils =====
def _now_local_str() -> str:
    """ÌòÑÏû¨ ÏãúÍ∞ÑÏùÑ KSTÎ°ú Î∞òÌôò"""
    kst = timezone(timedelta(hours=9))
    return datetime.now(kst).strftime("%Y-%m-%d %H:%M:%S")

def _now_utc() -> datetime:
    """ÌòÑÏû¨ ÏãúÍ∞ÑÏùÑ UTCÎ°ú Î∞òÌôò"""
    return datetime.now(timezone.utc)

def _to_kst(utc_dt: datetime) -> datetime:
    """UTC datetimeÏùÑ KSTÎ°ú Î≥ÄÌôò"""
    if utc_dt.tzinfo is None:
        utc_dt = utc_dt.replace(tzinfo=timezone.utc)
    kst = timezone(timedelta(hours=9))
    return utc_dt.astimezone(kst)

def _ensure_output_dir(model_name: str) -> str:
    try:
        os.makedirs(STORAGE_MODEL_ROOT, exist_ok=True)
    except PermissionError as e:
        raise InternalServerError(f"permission denied creating model root '{STORAGE_MODEL_ROOT}': {e}")
    except OSError as e:
        try:
            if getattr(e, "errno", None) == 13:
                raise InternalServerError(f"permission denied creating model root '{STORAGE_MODEL_ROOT}': {e}")
        except Exception:
            pass
        raise

    out_dir = os.path.join(STORAGE_MODEL_ROOT, model_name)
    try:
        os.makedirs(out_dir, exist_ok=True)
    except PermissionError as e:
        raise InternalServerError(f"permission denied creating output dir '{out_dir}': {e}")
    except OSError as e:
        try:
            if getattr(e, "errno", None) == 13:
                raise InternalServerError(f"permission denied creating output dir '{out_dir}': {e}")
        except Exception:
            pass
        raise
    cfg_path = os.path.join(out_dir, "config.json")
    if not os.path.isfile(cfg_path):
        try:
            with open(cfg_path, "w", encoding="utf-8") as f:
                json.dump({"created_at": _now_utc().isoformat()}, f, ensure_ascii=False)
        except Exception:
            logger.exception(f"failed to write config.json inside {out_dir}")
    return out_dir

def _ensure_lora_marker(out_dir: str, tuning_type: str):
    if tuning_type.upper() in ("LORA", "QLORA"):
        marker = os.path.join(out_dir, "adapter_config.json")
        if not os.path.isfile(marker):
            try:
                with open(marker, "w", encoding="utf-8") as f:
                    json.dump({"peft_type": "LORA", "tuning": tuning_type.upper()}, f, ensure_ascii=False)
            except Exception:
                logger.exception(f"failed to create LoRA marker {marker}")

def _append_log(log_path: str, line: str):
    try:
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(line.rstrip("\n") + "\n")
    except Exception:
        # Log but do not interrupt main flow
        logger.exception(f"failed to append log to {log_path}")

# ----- Error helper -----
def _write_error(out_dir: str, message: str):
    """Write error message to a dedicated error.txt inside output dir."""
    try:
        os.makedirs(out_dir, exist_ok=True)
        err_path = os.path.join(out_dir, "error.txt")
        with open(err_path, "a", encoding="utf-8") as f:
            ts = _now_utc().isoformat()
            f.write(f"[{ts}] {message}\n")
    except Exception:
        logger.exception(f"failed to write error file under {out_dir}")


# ===== DB ops =====
def _insert_dataset_if_needed(conn, path: str, category: str) -> int:
    # ==== ORM Î≤ÑÏ†Ñ ====
    # conn Ïù∏ÏûêÎäî Ìò∏ÌôòÏÑ± Ïú†ÏßÄÏö©ÏúºÎ°ú ÎÇ®Í≤®ÎëêÏßÄÎßå ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏùå
    rel_path = _to_rel(path)
    with get_session() as s:
        stmt = select(FineTuneDataset).where(FineTuneDataset.path == rel_path)
        exist = s.execute(stmt).scalars().first()
        if exist:
            return int(exist.id)
        
        # PostgreSQL ÏãúÌÄÄÏä§ ÎèôÍ∏∞Ìôî Î¨∏Ï†ú Ìï¥Í≤∞ÏùÑ ÏúÑÌïú ÏòàÏô∏ Ï≤òÎ¶¨
        try:
            row = FineTuneDataset(
                name=os.path.basename(path),
                category=category,
                prompt_id=None,  # ÏÉàÎ°ú Ï∂îÍ∞ÄÎêú ÌïÑÎìú (qnaÎäî None Í∞ÄÎä•)
                path=rel_path,
                record_count=None,
            )
            s.add(row)
            s.commit()
            s.refresh(row)
            return int(row.id)
        except Exception as e:
            # Ï§ëÎ≥µ ÌÇ§ ÏóêÎü¨Í∞Ä Î∞úÏÉùÌïú Í≤ΩÏö∞, Î°§Î∞± ÌõÑ Í∏∞Ï°¥ Î†àÏΩîÎìú Ï∞æÍ∏∞
            s.rollback()
            logger.warning(f"Dataset insert failed (likely sequence sync issue): {e}")
            
            # Îã§Ïãú ÌïúÎ≤à Í∏∞Ï°¥ Î†àÏΩîÎìú Ï∞æÍ∏∞
            stmt = select(FineTuneDataset).where(FineTuneDataset.path == rel_path)
            exist = s.execute(stmt).scalars().first()
            if exist:
                logger.info(f"Found existing dataset with id={exist.id} for path={rel_path}")
                return int(exist.id)
            
            # Í∑∏ÎûòÎèÑ ÏóÜÏúºÎ©¥ ÏµúÎåÄ IDÎ•º Ï∞æÏïÑÏÑú ÏàòÎèôÏúºÎ°ú ÏÉùÏÑ±
            try:
                from sqlalchemy import func, text
                # ÌòÑÏû¨ ÏµúÎåÄ ID ÌôïÏù∏
                max_id = s.execute(select(func.max(FineTuneDataset.id))).scalar() or 0
                next_id = max_id + 1
                
                # IDÎ•º Î™ÖÏãúÏ†ÅÏúºÎ°ú ÏÑ§Ï†ïÌï¥ÏÑú Ïû¨ÏãúÎèÑ
                row = FineTuneDataset(
                    id=next_id,
                    name=os.path.basename(path),
                    category=category,
                    prompt_id=None,
                    path=rel_path,
                    record_count=None,
                )
                s.add(row)
                s.commit()
                s.refresh(row)
                
                # ÏãúÌÄÄÏä§Î•º Îã§Ïùå IDÎ°ú ÏïàÏ†ÑÌïòÍ≤å ÏóÖÎç∞Ïù¥Ìä∏
                s.execute(text(f"SELECT setval('fine_tune_datasets_id_seq', {next_id}, true);"))
                s.commit()
                logger.info(f"Updated sequence to next value: {next_id + 1}")
                
                logger.info(f"Created dataset with manually assigned id={next_id}")
                return int(row.id)
            except Exception as e2:
                s.rollback()
                logger.error(f"Failed to create dataset with manual ID: {e2}")
                raise

def _insert_job(conn, category: str, req: FineTuneRequest, job_id: str, save_name_with_suffix: str, dataset_id: int,
                initial_status: str = "queued", scheduled_at: Optional[str] = None) -> int:
    # ==== ORM Î≤ÑÏ†Ñ ====
    reserve_now = _now_local_str()
    train_path = _resolve_train_path(req.trainSetFile)
    train_rel_path = _to_rel(train_path)
    hyper = {
        "systemPrompt": req.systemPrompt,
        "batchSize": req.batchSize,
        "epochs": req.epochs,
        "learningRate": req.learningRate,
        "overfittingPrevention": req.overfittingPrevention,
        "tuningType": (req.tuningType or "QLORA").upper(),
        "baseModelName": req.baseModelName,
        "saveModelName": save_name_with_suffix,
        "trainSetFile": train_rel_path,
        "reserveDate": reserve_now,
        "category": category,
        "subcategory": (req.subcategory or None),
        "gradientAccumulationSteps": req.gradientAccumulationSteps,
        "quantizationBits": req.quantizationBits,
    }
    metrics = {"hyperparameters": hyper}
    if scheduled_at:
        metrics["scheduledAt"] = scheduled_at
        metrics["learningProgress"] = 0

    with get_session() as s:
        row = ORMJob(
            provider_job_id=job_id,
            dataset_id=dataset_id,
            status=initial_status,
            started_at=None,  # Ïã§Ï†ú ÏãúÏûë ÏãúÏ†êÏóê ÏÑ§Ï†ï
            metrics=json.dumps(metrics, ensure_ascii=False),
        )
        s.add(row)
        s.commit()
        s.refresh(row)
        return int(row.id)

# _update_job_statusÎäî Ïù¥Ï†ú RepositoryÎ•º ÏÇ¨Ïö©ÌïòÍ±∞ÎÇò ÏßÅÏ†ë Íµ¨ÌòÑ
# Í∏∞Ï°¥ Î°úÏßÅÍ≥ºÏùò Ìò∏ÌôòÏÑ±ÏùÑ ÏúÑÌï¥ ÎûòÌçº Ìï®ÏàòÎ°ú Ïú†ÏßÄÌïòÎêò, repository Ìï®ÏàòÎ•º Ìò∏Ï∂ú
def _update_job_status(conn, job_id: str, status: str, progress: int | None = None, rough: int | None = None, extras: dict | None = None, _retries: int = 3):
    """
    repository/llm_finetuning.pyÏùò update_job_statusÎ•º Ìò∏Ï∂ú
    conn Ïù∏ÏûêÎäî Î¨¥ÏãúÎê® (repositoryÏóêÏÑú get_session ÏÇ¨Ïö©)
    """
    try:
        update_job_status(job_id, status, progress, extras, rough)
        
        # Additional logging
        out_dir = _resolve_out_dir_by_job(job_id)
        if out_dir:
            log_path = os.path.join(out_dir, "train.log")
            msg = f"status={status} progress={progress} rough={rough} extras={extras or {}}"
            _append_log(log_path, f"[{_now_utc().isoformat()}] {msg}")
            
    except Exception as e:
        logger.error(f"Failed to update job status: {e}")

def _resolve_out_dir_by_job(job_id: str) -> Optional[str]:
    # ORM Î≤ÑÏ†Ñ
    with get_session() as s:
        stmt = select(ORMJob).where(ORMJob.provider_job_id == job_id)
        job = s.execute(stmt).scalars().first()
        
        if not job:
            return None
            
        save_name = None
        if job.metrics:
            try:
                mt = json.loads(job.metrics) or {}
                hp = mt.get("hyperparameters") or {}
                save_name = hp.get("saveModelName")
            except Exception:
                pass
        
        if not save_name:
            return None
            
        return os.path.join(STORAGE_MODEL_ROOT, save_name)


# ===== Training (inline, real) =====
def _run_training_inline(job: FineTuneJob, save_name_with_suffix: str):
    """
    Unsloth gpt-oss(20B) ÎÖ∏Ìä∏Î∂Å ÌùêÎ¶ÑÏùÑ Î∞òÏòÅÌïú Í≤ΩÎüâ/ÏïàÏ†ï ÌååÏù¥ÌîÑÎùºÏù∏.
    """
    import gc
    try:
        # _update_job_status Ìò∏Ï∂ú (connÏùÄ NoneÏúºÎ°ú Ï†ÑÎã¨Ìï¥ÎèÑ Îê®, ÎÇ¥Î∂ÄÏóêÏÑú Î¨¥Ïãú)
        _update_job_status(None, job.job_id, "running", progress=0)

        out_dir = _ensure_output_dir(save_name_with_suffix)
        tuning_type = (job.request.get("tuningType") or "QLORA").upper()
        if tuning_type in ("LORA", "QLORA"):
            _ensure_lora_marker(out_dir, tuning_type)
        log_path = os.path.join(out_dir, "train.log")
        try:
            with open(log_path, "w", encoding="utf-8") as _tmp:
                _tmp.write("")
        except Exception:
            pass
        _append_log(log_path, f"[{_now_utc().isoformat()}] job {job.job_id} started (INLINE)")
        logger.info(
            f"Fine-tuning started jobId={job.job_id} type={tuning_type} base={job.request.get('baseModelName')} "
            f"save={save_name_with_suffix} data={job.request.get('trainSetFile')}"
        )

        # ‚úÖ ÏûÑÏãú Ï∫êÏãú Ìè¥Îçî
        tmpdir = tempfile.mkdtemp(prefix="ft_cache_")
        cache_keys = ["HF_HOME", "TRANSFORMERS_CACHE", "HF_DATASETS_CACHE", "XDG_CACHE_HOME", "UNSLOTH_CACHE_DIR", "TORCHINDUCTOR_CACHE_DIR"]
        old_cache = {k: os.environ.get(k) for k in cache_keys}
        for k in cache_keys:
            os.environ[k] = tmpdir

        # ===== Imports =====
        try:
            import pandas as pd
            import torch
            from transformers import (
                AutoModelForCausalLM,
                AutoTokenizer,
                TrainingArguments,
                Trainer,
                BitsAndBytesConfig,
                TrainerCallback,
                EarlyStoppingCallback,
            )
        except Exception as e:
            _append_log(log_path, f"[{_now_utc().isoformat()}] import error: {e}")
            fail_job(job.job_id, f"import error: {e}")
            logger.error(f"Fine-tuning failed jobId={job.job_id} error=import error: {e}")
            return

        # ===== Îç∞Ïù¥ÌÑ∞ Ï†ÅÏû¨/Ï†ÑÏ≤òÎ¶¨ =====
        system_prompt = job.request.get("systemPrompt") or "You are Qwen, a helpful assistant."
        def build_prompt(context: str, question: str) -> str:
            return f"{context.strip()}\n{system_prompt}\nQuestion: {question.strip()}"

        csv_path = _resolve_train_path(job.request.get("trainSetFile"))
        encodings_to_try = ["utf-8", "utf-8-sig", "cp949", "euc-kr", "latin1"]
        df = None
        for enc in encodings_to_try:
            try:
                df = pd.read_csv(csv_path, encoding=enc, dtype=str).fillna("")
                break
            except Exception:
                continue
        if df is None:
            try:
                import chardet
                with open(csv_path, "rb") as f:
                    raw = f.read(10000)
                enc = chardet.detect(raw).get("encoding") or "utf-8"
                df = pd.read_csv(csv_path, encoding=enc, dtype=str, on_bad_lines="skip").fillna("")
            except Exception as e:
                _append_log(log_path, f"[{_now_utc().isoformat()}] csv load failed: {e}")
                fail_job(job.job_id, f"csv load failed: {e}")
                logger.error(f"Fine-tuning failed jobId={job.job_id} error=csv load failed: {e}")
                return

        conversations = [{
            "conversations": [
                {"from": "user", "value": build_prompt(r.get("Chunk_Context",""), r.get("Question",""))},
                {"from": "assistant", "value": r.get("Answer","")},
            ]
        } for _, r in df.iterrows()]

        # ===== 7:3 Í≥†Ï†ï split (random_state=42) =====
        total = len(conversations)
        eval_size = max(1, int(round(total * 0.3))) if total >= 2 else 0
        if eval_size > 0:
            import random as _R
            idx = list(range(total))
            rng = _R.Random(42)
            rng.shuffle(idx)
            eval_idx = set(idx[:eval_size])
            train_data = [conversations[i] for i in idx[eval_size:]]
            eval_data  = [conversations[i] for i in idx[:eval_size]]
        else:
            train_data, eval_data = conversations, []
        _append_log(log_path, f"[{_now_utc().isoformat()}] split: total={total} eval={eval_size} train={len(train_data)}")

        class RagDataset(torch.utils.data.Dataset):
            def __init__(self, data, tokenizer, max_len=4096):
                self.data = data
                self.tk = tokenizer
                self.max_len = max_len
            def __len__(self): return len(self.data)
            def __getitem__(self, i):
                dialog = self.data[i]["conversations"]
                messages = [
                    {"role": "system", "content": "You are Qwen, a helpful assistant."},
                    {"role": "user", "content": dialog[0]["value"]},
                    {"role": "assistant", "content": dialog[1]["value"]},
                ]
                full = self.tk.apply_chat_template(messages, tokenize=False)
                enc = self.tk(full, max_length=self.max_len, truncation=True, padding="max_length", return_tensors="pt")
                input_ids = enc.input_ids[0]
                assist = self.tk.apply_chat_template(messages[:-1], tokenize=False, add_generation_prompt=True)
                prefix_len = len(self.tk(assist).input_ids)
                labels = input_ids.clone()
                labels[:prefix_len] = -100
                return {"input_ids": input_ids, "attention_mask": enc.attention_mask[0], "labels": labels}

        base_folder = _resolve_model_dir(job.request.get("baseModelName"))
        if not _has_model_signature(base_folder):
            msg = f"base model not found: {base_folder}"
            _append_log(log_path, f"[{_now_utc().isoformat()}] {msg}")
            fail_job(job.job_id, msg)
            logger.error(f"Fine-tuning failed jobId={job.job_id} error={msg}")
            return

        model_path = base_folder
        output_dir = os.path.join(STORAGE_MODEL_ROOT, save_name_with_suffix)
        is_mxfp4 = _looks_like_mxfp4_model(model_path) or _looks_like_mxfp4_model(job.request.get("baseModelName"))

        # ===== Î™®Îç∏/ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î°úÎìú =====
        # gpt-oss(MXFP4) ‚Üí Unsloth
        if tuning_type == "QLORA" and is_mxfp4:
            # üéØ Ïó¨Í∏∞ÏÑúÎßå unsloth import ‚Üí Gemma/QwenÏóêÎäî Ìå®ÏπòÍ∞Ä Ï†ÅÏö©ÎêòÏßÄ ÏïäÏùå
            from unsloth import FastLanguageModel  # type: ignore
            max_len = int(job.request.get("max_len", 3072))  # üí° Í∏∞Î≥∏ 3072Î°ú ÏÇ¥Ïßù ÎÇÆÏ∂∞ OOM ÏòàÎ∞©
            model, tokenizer = FastLanguageModel.from_pretrained(
                model_name=model_path,
                dtype=None,                    # H100 ‚Üí bf16 ÏûêÎèô
                max_seq_length=max_len,
                load_in_4bit=True,
                full_finetuning=False,
                trust_remote_code=True,
                local_files_only=True,
            )
            # Unsloth Î™®Î≤îÏÇ¨Î°Ä: ÌïôÏäµ ÏµúÏ†ÅÌôî ÌôúÏÑ±Ìôî
            try:
                model = FastLanguageModel.for_training(model)  # ÏùºÎ∂Ä Î≤ÑÏ†ÑÏóêÏÑ† in-place. Î∞òÌôòÍ∞í Ìò∏Ìôò.
            except Exception:
                pass
            try:
                model = FastLanguageModel.get_peft_model(
                    model,
                    r=64,
                    lora_alpha=16,
                    lora_dropout=0.05,
                    bias="none",
                )
            except Exception:
                from peft import LoraConfig, get_peft_model  # type: ignore
                lora_cfg = LoraConfig(r=64, lora_alpha=16, lora_dropout=0.05, bias="none", task_type="CAUSAL_LM")
                model = get_peft_model(model, lora_cfg)

        elif tuning_type == "QLORA":
            # ÏùºÎ∞ò QLORA
            from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training  # type: ignore
            bnb = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_use_double_quant=True,
                bnb_4bit_quant_type="nf4",
                bnb_4bit_compute_dtype=torch.bfloat16,
            )
            tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, local_files_only=True)
            if tokenizer.pad_token_id is None:
                if getattr(tokenizer, "eos_token_id", None) is not None:
                    tokenizer.pad_token_id = tokenizer.eos_token_id
                else:
                    tokenizer.add_special_tokens({"pad_token": "<|pad|>"})
                    tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids("<|pad|>")
            model = AutoModelForCausalLM.from_pretrained(
                model_path,
                trust_remote_code=True,
                device_map="auto",
                quantization_config=bnb,
                local_files_only=True,
            )
            model.gradient_checkpointing_enable()
            model = prepare_model_for_kbit_training(model)
            lora_targets = [
                "q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj",
                "down_proj","w1","w2","c_proj","c_attn"
            ]
            from itertools import chain
            target_modules = sorted({
                n.split(".")[-1]
                for n, _ in model.named_modules()
                if any(k in n for k in lora_targets)
            })
            lora_cfg = LoraConfig(
                r=64, lora_alpha=16, target_modules=(target_modules or None),
                lora_dropout=0.05, bias="none", task_type="CAUSAL_LM",
            )
            model = get_peft_model(model, lora_cfg)
            max_len = int(job.request.get("max_len", 4096))
        elif tuning_type == "LORA":
            from peft import LoraConfig, get_peft_model  # type: ignore
            tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, local_files_only=True)
            if tokenizer.pad_token_id is None:
                if getattr(tokenizer, "eos_token_id", None) is not None:
                    tokenizer.pad_token_id = tokenizer.eos_token_id
                else:
                    tokenizer.add_special_tokens({"pad_token": "<|pad|>"})
                    tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids("<|pad|>")
            model = AutoModelForCausalLM.from_pretrained(
                model_path,
                trust_remote_code=True,
                device_map="auto",
                torch_dtype=torch.bfloat16,
                local_files_only=True,
            )
            model.gradient_checkpointing_enable()
            targets = [
                "q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj",
                "down_proj","w1","w2","c_proj","c_attn"
            ]
            target_modules = sorted({ n.split(".")[-1] for n,_ in model.named_modules() if any(k in n for k in targets) })
            lora_cfg = LoraConfig(r=64, lora_alpha=16, target_modules=(target_modules or None), lora_dropout=0.05, bias="none", task_type="CAUSAL_LM")
            model = get_peft_model(model, lora_cfg)
            max_len = int(job.request.get("max_len", 4096))
        else:  # FULL
            tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, local_files_only=True)
            if tokenizer.pad_token_id is None:
                if getattr(tokenizer, "eos_token_id", None) is not None:
                    tokenizer.pad_token_id = tokenizer.eos_token_id
                else:
                    tokenizer.add_special_tokens({"pad_token": "<|pad|>"})
                    tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids("<|pad|>")
            model = AutoModelForCausalLM.from_pretrained(
                model_path, trust_remote_code=True, device_map="auto", torch_dtype=torch.bfloat16, local_files_only=True,
            )
            model.gradient_checkpointing_enable()
            for p in model.parameters(): p.requires_grad = True
            max_len = int(job.request.get("max_len", 4096))

        # ===== Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ± =====
        train_ds = RagDataset(train_data, tokenizer, max_len=max_len)
        eval_ds  = RagDataset(eval_data,  tokenizer, max_len=max_len) if eval_size > 0 else None
        use_eval = eval_ds is not None and len(eval_data) > 0

        # ===== Overfitting prevention: Early Stopping =====
        # ÏöîÍµ¨ÏÇ¨Ìï≠: overfittingPrevention=TrueÎ©¥, eval Í∞úÏÑ†Ïù¥ ÏóÜÏùÑ Îïå ÏûêÎèôÏúºÎ°ú ÌïôÏäµ Ï§ëÎã®
        overfit_prevent = bool(job.request.get("overfittingPrevention", True))
        early_stop_enabled = bool(overfit_prevent and use_eval)
        early_stop_patience = int(ft_conf.get("early_stopping_patience", 2))
        early_stop_threshold = float(ft_conf.get("early_stopping_threshold", 0.0))

        # ===== TrainingArguments (Î≤ÑÏ†Ñ Ìò∏Ìôò ÌÇ§ ÏûêÎèô Îß§Ìïë) =====
        from inspect import signature as _sig
        def _supported_args(cls): return set(_sig(cls.__init__).parameters.keys())
        def _put_kw(supported: set, kw: dict, key: str, value, *aliases: str):
            for k in (key, *aliases):
                if k in supported:
                    kw[k] = value
                    return k
            return None

        # config.yamlÏùò fine_tuning ÏÑπÏÖòÏóêÏÑú optimizer ÏÑ§Ï†ïÏùÑ Í∞ÄÏ†∏Ïò§Í±∞ÎÇò Í∏∞Î≥∏Í∞í ÏÇ¨Ïö©
        ft_optim = ft_conf.get("optimizer")
        if ft_optim:
            optim_name = ft_optim
        else:
            optim_name = "adamw_torch" if tuning_type in ("FULL", "LORA") else "paged_adamw_8bit"
        save_strategy_val = "epoch" if use_eval else "no"
        eval_strategy_val = "epoch" if use_eval else "no"

        _ta = dict(
            output_dir=output_dir,
            num_train_epochs=job.request.get("epochs", 3),
            per_device_train_batch_size=job.request.get("batchSize", 1),
            gradient_accumulation_steps=job.request.get("gradientAccumulationSteps", 8),
            learning_rate=job.request.get("learningRate", 2e-4),
            bf16=True,
            logging_steps=10,
            report_to="none",
            optim=optim_name,
            seed=42,
            data_seed=42,
            save_total_limit=2,
            warmup_ratio=0.05,
        )
        sup = _supported_args(TrainingArguments)
        _put_kw(sup, _ta, "save_strategy", save_strategy_val)
        _put_kw(sup, _ta, "evaluation_strategy", eval_strategy_val, "eval_strategy")
        _put_kw(sup, _ta, "gradient_checkpointing", True)
        _put_kw(sup, _ta, "lr_scheduler_type", "cosine")
        _put_kw(sup, _ta, "save_safetensors", True)
        if use_eval:
            _put_kw(sup, _ta, "load_best_model_at_end", True)
            _put_kw(sup, _ta, "metric_for_best_model", "eval_loss")
            _put_kw(sup, _ta, "greater_is_better", False)
            _put_kw(sup, _ta, "per_device_eval_batch_size", max(1, job.request.get("batchSize", 1)))
        if early_stop_enabled:
            # EarlyStoppingCallbackÏù¥ ÎèôÏûëÌïòÎ†§Î©¥ evalÏù¥ Ï£ºÍ∏∞Ï†ÅÏúºÎ°ú ÎèåÏïÑÏïº Ìï®.
            # ÎòêÌïú load_best_model_at_end + metric_for_best_modelÏù¥ ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÏñ¥Ïïº Ìï®.
            _append_log(
                log_path,
                f"[{_now_utc().isoformat()}] early_stopping enabled: "
                f"patience={early_stop_patience} threshold={early_stop_threshold}",
            )

        training_args = TrainingArguments(**_ta)

        # ===== ÏΩúÎ∞± =====
        class ProgressCallback(TrainerCallback):
            def __init__(self, job_id: str, every_steps: int | None = None):
                self.job_id = job_id
                self.every_steps = every_steps if every_steps else max(1, int(ft_conf.get("progress_every_steps", 1)))
                self.total_steps = None
            def on_train_begin(self, args, state, control, **kw):
                _update_job_status(None, self.job_id, "running", progress=0)
            def on_train_begin_dataloader(self, args, state, control, **kw):
                try:
                    if state.max_steps and state.max_steps > 0:
                        self.total_steps = int(state.max_steps)
                except Exception:
                    pass
            def on_step_end(self, args, state, control, **kw):
                try:
                    total = self.total_steps or (state.max_steps or 0)
                    if not total or state.global_step % self.every_steps != 0: return
                    pct = int(min(100, max(0, round((state.global_step/total)*100))))
                    _update_job_status(None, self.job_id, "running", progress=pct)
                except Exception:
                    pass
            def on_train_end(self, args, state, control, **kw):
                _update_job_status(None, self.job_id, "running", progress=100)

        class LogCallback(TrainerCallback):
            def on_log(self, args, state, control, logs=None, **kw):
                if logs and "loss" in logs:
                    _append_log(log_path, f"[{_now_utc().isoformat()}] step={state.global_step} loss={logs['loss']}")

        def _build_trainer():
            callbacks = [ProgressCallback(job.job_id), LogCallback()]
            if early_stop_enabled:
                callbacks.append(
                    EarlyStoppingCallback(
                        early_stopping_patience=early_stop_patience,
                        early_stopping_threshold=early_stop_threshold,
                    )
                )
            return Trainer(
                model=model,
                args=training_args,
                train_dataset=train_ds,
                eval_dataset=eval_ds,
                tokenizer=tokenizer,  # FutureWarningÏùÄ Î¨¥Ïãú Í∞ÄÎä• (Ï∂îÌõÑ processing_classÎ°ú ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò)
                callbacks=callbacks,
            )

        trainer = _build_trainer()

        # ===== ÌïôÏäµ + OOM ÏÑ∏Ïù¥ÌîÑ Ïû¨ÏãúÎèÑ =====
        import math
        try:
            _append_log(log_path, f"[{_now_utc().isoformat()}] training started...")
            trainer.train()
        except RuntimeError as re:
            if "out of memory" in str(re).lower():
                # üîª Î∞∞Ïπò/ÏãúÌÄÄÏä§ ÎèôÏãú Ï∂ïÏÜå + **Ïù¥Ï†Ñ Trainer/Í∑∏ÎûòÌîÑ ÏôÑÏ†Ñ Ï†ïÎ¶¨**
                old_bs = training_args.per_device_train_batch_size
                new_bs = max(1, old_bs // 2)
                new_len = max(1024, int(max_len * 0.75))
                _append_log(log_path, f"[{_now_utc().isoformat()}] OOM ‚Üí retry with batch={new_bs}, max_len={new_len}")
                # Î©îÎ™®Î¶¨ Ìï¥Ï†ú
                try:
                    del trainer
                    torch.cuda.empty_cache(); gc.collect()
                except Exception:
                    pass
                # Ïû¨Íµ¨ÏÑ±
                training_args.per_device_train_batch_size = new_bs
                train_ds = RagDataset(train_data, tokenizer, max_len=new_len)
                eval_ds  = RagDataset(eval_data,  tokenizer, max_len=new_len) if use_eval else None
                trainer = Trainer(
                    model=model,
                    args=training_args,
                    train_dataset=train_ds,
                    eval_dataset=eval_ds,
                    tokenizer=tokenizer,
                    callbacks=[ProgressCallback(job.job_id), LogCallback()],
                )
                trainer.train()
            else:
                raise

        # ===== Í∞ÑÎã® ROUGE-1 (ÏòµÏÖîÎÑê) =====
        def _rouge1_f1(ref: str, cand: str) -> float:
            rw, cw = ref.split(), cand.split()
            if not rw or not cw: return 0.0
            m = sum(1 for w in cw if w in rw)
            p = m/len(cw) if cw else 0.0
            r = m/len(rw) if rw else 0.0
            return 0.0 if (p+r)==0 else 2*(p*r)/(p+r)

        final_rouge = None
        if use_eval:
            model.eval()
            preds, refs = [], []
            device = _get_model_device(model)
            for item in eval_ds:
                inp_ids = item["input_ids"].unsqueeze(0).to(device)
                attn = item["attention_mask"].unsqueeze(0).to(device)
                try:
                    with torch.inference_mode():
                        out_ids = model.generate(
                            inp_ids,
                            attention_mask=attn,
                            max_new_tokens=128,
                            do_sample=False,
                        )[0]
                except Exception:
                    continue
                preds.append(tokenizer.decode(out_ids, skip_special_tokens=True))
                ref_ids = item["labels"]
                ref_ids = torch.where(ref_ids == -100, torch.tensor(tokenizer.pad_token_id), ref_ids)
                refs.append(tokenizer.decode(ref_ids, skip_special_tokens=True))
            scores = [_rouge1_f1(r, p) for r, p in zip(refs, preds)]
            if scores: final_rouge = sum(scores) / len(scores)
            _update_job_status(None, job.job_id, "running", rough=int((final_rouge or 0)*100), extras={"rouge1F1": final_rouge})

        # ===== Ï†ÄÏû• =====
        def _save_stage(stage: str, pct: int):
            _append_log(log_path, f"[{_now_utc().isoformat()}] save:{stage} {pct}%")
            _update_job_status(None, job.job_id, "running", extras={"saveStage": stage, "saveProgress": pct})

        _save_stage("start", 5)
        _append_log(log_path, f"[{_now_utc().isoformat()}] saving model...")

        if tuning_type in ("LORA", "QLORA"):
            try:
                model.save_pretrained(output_dir)     # Ïñ¥ÎåëÌÑ∞Îßå Ï†ÄÏû•
                _save_stage("adapter", 70)
                tokenizer.save_pretrained(output_dir)
                _save_stage("tokenizer", 90)
                _append_log(log_path, f"[{_now_utc().isoformat()}] saved adapters ‚Üí {output_dir}")
            except Exception as e:
                trainer.save_model(output_dir)
                _save_stage("model", 70)
                tokenizer.save_pretrained(output_dir)
                _save_stage("tokenizer", 90)
                _append_log(log_path, f"[{_now_utc().isoformat()}] fallback save (trainer.save_model): {e}")
            # MXFP4 Î≥ëÌï© Ï†ÄÏû•ÏùÄ ÏÑ†ÌÉù(Í∏∞Î≥∏ ÎπÑÌôúÏÑ±)
            if is_mxfp4 and ft_conf.get("unsloth_merge_save", False):
                try:
                    model.save_pretrained_merged(output_dir, tokenizer, save_method="mxfp4")
                    _append_log(log_path, f"[{_now_utc().isoformat()}] merged MXFP4 saved ‚Üí {output_dir}")
                except Exception as e:
                    _append_log(log_path, f"[{_now_utc().isoformat()}] MXFP4 merge save failed: {e}, adapters only.")
        else:
            trainer.save_model(output_dir)
            _save_stage("model", 70)
            tokenizer.save_pretrained(output_dir)
            _save_stage("tokenizer", 90)

        _save_stage("done", 100)

        finish_job_success(
            job.job_id, save_name_with_suffix, job.category, tuning_type, final_rouge, subcategory=job.request.get("subcategory"),
        )
        logger.info(f"Fine-tuning succeeded jobId={job.job_id} save={save_name_with_suffix} type={tuning_type}")
        _append_log(log_path, f"[{_now_utc().isoformat()}] job {job.job_id} succeeded")

    except Exception as e:
        logger.error(f"Fine-tuning failed jobId={job.job_id} error={e}")
        try:
            _append_log(os.path.join(STORAGE_MODEL_ROOT, save_name_with_suffix, "train.log"), f"[{_now_utc().isoformat()}] error: {e}")
        except Exception:
            pass
        
        fail_job(job.job_id, str(e))
        
    finally:
        # ÏûêÏõê Ï†ïÎ¶¨
        try:
            del trainer
        except Exception:
            pass
        try:
            del model, tokenizer
        except Exception:
            pass
        try:
            import torch
            gc.collect()
            if hasattr(torch, "cuda") and torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.ipc_collect()
        except Exception:
            pass
        try:
            for k, v in old_cache.items():
                if v is None: os.environ.pop(k, None)
                else: os.environ[k] = v
            shutil.rmtree(tmpdir, ignore_errors=True)
        except Exception:
            pass
        # conn.close()  <-- Ï†úÍ±∞Îê®

# ===== Public APIs =====
def _log_to_save_name(save_name_with_suffix: str, message: str):
    try:
        out_dir = _ensure_output_dir(save_name_with_suffix)
        log_path = os.path.join(out_dir, "train.log")
        _append_log(log_path, f"[{_now_utc().isoformat()}] {message}")
    except Exception:
        pass

def start_fine_tuning(category: str, body: FineTuneRequest) -> Dict[str, Any]:
    # startNowÏôÄ startAt ÎèôÏãú ÏßÄÏ†ï Î∞©ÏßÄ
    if body.startNow and body.startAt:
        raise BadRequestError("startNowÏôÄ startAtÏùÄ ÎèôÏãúÏóê ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§. (Îëò Ï§ë ÌïòÎÇòÎßå)")
    
    # body.categoryÎ•º ÏµúÏ¢Ö Ïã†Î¢∞(ÌïòÏúÑÌò∏ÌôòÏùÑ ÏúÑÌï¥ Ïù∏Ïàò categoryÎäî fallback)
    category = (body.category or category).lower()
    suffix = (body.tuningType or "QLORA").upper()
    # Ïπ¥ÌÖåÍ≥†Î¶¨ÍπåÏßÄ Ìè¨Ìï®ÌïòÏó¨ Ï†ÄÏû• Ìè¥Îçî/Î™®Îç∏Î™ÖÏùÑ Íµ¨Î∂Ñ (Ïòà: name-QLORA-qa)
    save_name_with_suffix = f"{body.saveModelName}-{suffix}-{category}"
    _ensure_output_dir(save_name_with_suffix)
    
    # Ï§ëÎ≥µ Ïã§Ìñâ Ï∞®Îã® (ÎùΩ ÌååÏùº)
    import fcntl
    out_dir = _ensure_output_dir(save_name_with_suffix)
    lock_path = os.path.join(out_dir, ".run.lock")
    lock_f = open(lock_path, "w")
    try:
        fcntl.flock(lock_f, fcntl.LOCK_EX | fcntl.LOCK_NB)
        lock_f.write(f"locked at {_now_utc().isoformat()}\n")
        lock_f.flush()
    except BlockingIOError:
        lock_f.close()
        raise BadRequestError(f"another fine-tune is already running for {save_name_with_suffix}")

    base_dir = _resolve_model_dir(body.baseModelName)
    if not _has_model_signature(base_dir):
        msg = f"base model not found: {base_dir}"
        logger.error(msg)
        _log_to_save_name(save_name_with_suffix, msg)
        raise BadRequestError(msg)

    job_id = f"ft-job-{uuid.uuid4().hex[:12]}"

    try:
        train_path = _resolve_train_path(body.trainSetFile)
        dataset_id = _insert_dataset_if_needed(None, train_path, category) # conn Ïù∏Ïûê None Ï†ÑÎã¨
        # ÏòàÏïΩ ÏãúÍ∞Ñ ÌååÏã±
        scheduled_at_iso = None
        delay_sec = 0.0
        if body.startAt:
            try:
                scheduled_dt = datetime.fromisoformat(body.startAt)
                # timezone Ï†ïÎ≥¥Í∞Ä ÏóÜÏúºÎ©¥ KSTÎ°ú Í∞ÄÏ†ï
                if scheduled_dt.tzinfo is None:
                    kst = timezone(timedelta(hours=9))
                    scheduled_dt = scheduled_dt.replace(tzinfo=kst)
                now_dt = _now_utc()
                delta = (scheduled_dt - now_dt).total_seconds()
                if delta > 1.0:
                    delay_sec = float(delta)
                    scheduled_at_iso = scheduled_dt.isoformat()
            except Exception:
                scheduled_at_iso = None
                delay_sec = 0.0

        _insert_job(
            None, category, body, job_id, save_name_with_suffix, dataset_id, # conn Ïù∏Ïûê None
            initial_status=("scheduled" if delay_sec > 1.0 else "queued"),
            scheduled_at=scheduled_at_iso,
        )
    except Exception as e:
        _log_to_save_name(save_name_with_suffix, f"db insert failed: {e}")
        logger.error(f"fine-tuning init failed: {e}")
        raise InternalServerError(f"fine-tuning init failed: {e}")
    finally:
        pass
        # conn.close() <-- Ï†úÍ±∞Îê®

    job = FineTuneJob(job_id=job_id, category=category, request=body.model_dump())
    
    # üîπ Ï¶âÏãú Ïã§ÌñâÏù¥Î©¥ ÏòàÏïΩ(startAt)ÏùÄ **Î¨¥Ïãú**Ìï¥ÏÑú Ï§ëÎ≥µ Ïã§ÌñâÏùÑ ÏõêÏ≤ú Ï∞®Îã®
    if body.startNow:
        def _launch():
            _run_training_inline(job, save_name_with_suffix)
        t = threading.Thread(target=_launch, daemon=True)
        t.start()
        logger.info(
            f"Fine-tuning started immediately jobId={job.job_id} category={category} base={body.baseModelName} "
            f"save={save_name_with_suffix} tuning={body.tuningType or 'QLORA'}"
        )
        return {"jobId": job_id, "started": True}
    else:
        # ÏòàÏïΩ Ïã§Ìñâ ÎòêÎäî ÌÅêÏóêÎßå Îì±Î°ù
        if body.startAt:
            # ÏòàÏïΩ Ïã§Ìñâ
            def _launch():
                _run_training_inline(job, save_name_with_suffix)
            
            # ÏòàÏïΩ ÎîúÎ†àÏù¥ Ïû¨Í≥ÑÏÇ∞
            delay_sec = 0.0
            try:
                scheduled_dt = datetime.fromisoformat(body.startAt)
                # timezone Ï†ïÎ≥¥Í∞Ä ÏóÜÏúºÎ©¥ KSTÎ°ú Í∞ÄÏ†ï
                if scheduled_dt.tzinfo is None:
                    kst = timezone(timedelta(hours=9))
                    scheduled_dt = scheduled_dt.replace(tzinfo=kst)
                now_dt = _now_utc()
                delta = (scheduled_dt - now_dt).total_seconds()
                if delta > 1.0:
                    delay_sec = float(delta)
            except Exception:
                delay_sec = 0.0

            if delay_sec > 1.0:
                t = threading.Timer(delay_sec, _launch)
                t.daemon = True
                t.start()
                logger.info(
                    f"Fine-tuning scheduled jobId={job.job_id} at {scheduled_dt.isoformat()} category={category} base={body.baseModelName} save={save_name_with_suffix}"
                )
            else:
                # ÏòàÏïΩ ÏãúÍ∞ÑÏù¥ Ïù¥ÎØ∏ ÏßÄÎÇ¨ÏúºÎ©¥ Ï¶âÏãú Ïã§Ìñâ
                t = threading.Thread(target=_launch, daemon=True)
                t.start()
                logger.info(
                    f"Fine-tuning started (scheduled time passed) jobId={job.job_id} category={category} base={body.baseModelName} save={save_name_with_suffix}"
                )
        else:
            # ÌÅêÏóêÎßå Îì±Î°ù (Ïä§ÏºÄÏ§ÑÎü¨Í∞Ä ÎÇòÏ§ëÏóê Ïã§Ìñâ)
            try:
                _update_job_status(None, job_id, "queued", extras={"reserved": True, "reservedAt": _now_local_str()})
            finally:
                pass
            logger.info(
                f"Fine-tuning queued (not started) jobId={job.job_id} category={category} base={body.baseModelName} save={save_name_with_suffix}"
            )

    return {"jobId": job_id, "started": bool(body.startNow)}

def get_fine_tuning_status(job_id: str) -> Dict[str, Any]:
    with get_session() as s:
        # ORM Î≤ÑÏ†Ñ
        stmt = select(ORMJob).where(ORMJob.provider_job_id == job_id)
        row = s.execute(stmt).scalars().first()
        
        if not row:
            return {"error": "job not found", "jobId": job_id}
            
        metrics = {}
        if row.metrics:
            try:
                metrics = json.loads(row.metrics) or {}
            except Exception:
                metrics = {}

        # Liveness check
        row_status = row.status
        try:
            if row_status == "running":
                hb = metrics.get("heartbeatAt")
                if hb:
                    from dateutil import parser as dtparser
                    last = dtparser.parse(hb)
                    now = _now_utc()
                    if (now - last).total_seconds() > FT_HEARTBEAT_TIMEOUT_SEC:
                        fail_job(job_id, "stale heartbeat")
                        row_status = "failed"
        except Exception:
            pass

        return {
            "jobId": row.provider_job_id,
            "status": row_status,
            "learningProgress": int(metrics.get("learningProgress", 0)),
            "roughScore": int(metrics.get("roughScore", 0)),
            "rouge1F1": metrics.get("rouge1F1"),
            "saveProgress": int(metrics.get("saveProgress", 0)),
            "saveStage": metrics.get("saveStage"),
            "error": metrics.get("error"),
        }

_FEEDBACK_FILE_RE = re.compile(r"^feedback_(qna|doc_gen|summary)_p(\d+)\.csv$", re.IGNORECASE)

def list_feedback_datasets() -> dict:
    """
    ./storage/train_data ÏïàÏóêÏÑú ÌååÏùºÎ™Ö Ìå®ÌÑ¥
    'feedback_{task}_p{prompt}.csv'Ïóê Îß§Ïπ≠ÎêòÎäî Î™®Îì† CSVÎ•º ÌÖåÏä§ÌÅ¨Î≥ÑÎ°ú Î∞òÌôò.
    Î∞òÌôò Í≤ΩÎ°úÎäî ÏÉÅÎåÄÍ≤ΩÎ°ú('./storage/train_data/...')Î•º Ï†úÍ≥µÌïúÎã§.
    """
    REL_ROOT = "./storage/train_data"

    try:
        names = sorted(os.listdir(TRAIN_DATA_ROOT))
    except FileNotFoundError:
        names = []

    entries = []
    for name in names:
        m = _FEEDBACK_FILE_RE.match(name)
        if not m:
            continue
        task = m.group(1).lower()
        prompt = int(m.group(2))
        abs_path = os.path.join(TRAIN_DATA_ROOT, name)
        if not os.path.isfile(abs_path):
            continue
        st = os.stat(abs_path)
        mtime_dt = datetime.fromtimestamp(st.st_mtime)
        entries.append({
            "task": task,                               # qna | doc_gen | summary
            "file": name,                               # ex) feedback_qna_p0.csv
            "prompt": prompt,                           # Ï†ïÏàò pÍ∞í
            "bytes": st.st_size,                        # ÌååÏùº ÌÅ¨Í∏∞
            "mtime": mtime_dt.strftime("%Y-%m-%d %H:%M:%S"),
            "mtime_iso": mtime_dt.isoformat(),
            "path": f"{REL_ROOT}/{name}",               # ÏÉÅÎåÄÍ≤ΩÎ°ú (Docker Í≥†Î†§)
            "downloadUrl": f"/v1/admin/llm/feedback-datasets?file={quote_plus(name)}",
        })

    groups = {"qna": [], "doc_gen": [], "summary": []}
    for e in entries:
        groups[e["task"]].append(e)
    for k in groups:
        groups[k].sort(key=lambda x: x["prompt"])

    return {
        "root": REL_ROOT,
        "pattern": "feedback_{task}_p{prompt}.csv",
        "total": len(entries),
        "counts": {k: len(v) for k, v in groups.items()},
        "groups": groups,
    }

def resolve_feedback_download(file: str) -> tuple[str, str]:
    """
    Îã§Ïö¥Î°úÎìúÏö© ÌååÏùº Í≤ÄÏ¶ù/Ìï¥Í≤∞:
    - basenameÎßå ÌóàÏö© (Í≤ΩÎ°ú ÌÉàÏ∂ú Î∞©ÏßÄ)
    - ÌååÏùºÎ™Ö Ìå®ÌÑ¥ ÌôïÏù∏
    - ./storage/train_data ÎÇ¥Î∂Ä Ï°¥Ïû¨ ÌôïÏù∏
    ÏÑ±Í≥µ Ïãú: (abs_path, filename) Î∞òÌôò
    """
    if os.path.basename(file) != file:
        raise BadRequestError("basenameÎßå ÌóàÏö©Ìï©ÎãàÎã§.")
    m = _FEEDBACK_FILE_RE.match(file)
    if not m:
        raise BadRequestError("ÏûòÎ™ªÎêú ÌååÏùºÎ™Ö ÌòïÏãùÏûÖÎãàÎã§. (feedback_{task}_p{n}.csv)")
    abs_path = os.path.join(TRAIN_DATA_ROOT, file)
    if not os.path.isfile(abs_path):
        # ÎùºÏö∞ÌÑ∞ÏóêÏÑú 404Î°ú Îß§ÌïëÌïòÍ∏∞ ÏúÑÌï¥ ÌëúÏ§Ä ÏòàÏô∏ ÏÇ¨Ïö©
        raise FileNotFoundError(f"not found in {TRAIN_DATA_ROOT}: {file}")
    return abs_path, file
