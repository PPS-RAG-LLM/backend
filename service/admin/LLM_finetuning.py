# service/admin/LLM_finetuning.py
from __future__ import annotations

# âœ… UnslothëŠ” transformers/peft ë³´ë‹¤ ë¨¼ì € import
try:
    import unsloth  # noqa: F401
except Exception:
    pass

import os
# ğŸ”§ CUDA ë©”ëª¨ë¦¬ ë‹¨í¸í™” ì™„í™” (ê¶Œì¥)
os.environ.setdefault("PYTORCH_CUDA_ALLOC_CONF", "max_split_size_mb:512,expandable_segments:True,roundup_power2_divisions:16")

import json
import threading
import time
import uuid
import tempfile
import shutil
from dataclasses import dataclass
from datetime import datetime, timezone, timedelta
from typing import Any, Dict, Optional
from pathlib import Path
from contextlib import contextmanager

from pydantic import BaseModel, Field, field_validator, model_validator
from utils import logger
from errors.exceptions import BadRequestError, InternalServerError

# --- Repository Imports ---
from repository.llm_finetuning import update_job_status, finish_job_success, fail_job
from utils.database import get_session

logger = logger(__name__)

import re
from urllib.parse import quote_plus
_FEEDBACK_FILE_RE = re.compile(r"^feedback_(qna|doc_gen|summary)_p(\d+)\.csv$", re.IGNORECASE)

# ===== ë””ë°”ì´ìŠ¤ ìœ í‹¸ =====
def _get_model_device(model):
    try:
        return model.get_input_embeddings().weight.device
    except Exception:
        pass
    try:
        return next(model.parameters()).device
    except Exception:
        pass
    import torch as _torch
    return _torch.device("cuda" if _torch.cuda.is_available() else "cpu")


def _clear_gpu_memory():
    """GPU ë©”ëª¨ë¦¬ ìºì‹œë¥¼ ì™„ì „íˆ ì •ë¦¬í•˜ì—¬ ë‹¨í¸í™”ë¥¼ ì¤„ì…ë‹ˆë‹¤."""
    try:
        import torch
        import gc
        if hasattr(torch, "cuda") and torch.cuda.is_available():
            # ëª¨ë“  CUDA ìºì‹œ ì •ë¦¬
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
            # Python GC ì‹¤í–‰
            gc.collect()
            # ë‹¤ì‹œ í•œë²ˆ ìºì‹œ ì •ë¦¬
            torch.cuda.empty_cache()
            logger.debug("GPU memory cache cleared")
    except Exception as e:
        logger.warning(f"Failed to clear GPU memory: {e}")


# ===== ìºì‹œ/ì„ì‹œ ë””ë ‰í† ë¦¬ ê´€ë¦¬ =====
@contextmanager
def _ephemeral_cache_env():
    """í›ˆë ¨ ì¤‘ì—ë§Œ ì„ì‹œ ìºì‹œ ë””ë ‰í† ë¦¬ë¥¼ ì‚¬ìš©í•˜ê³  ëë‚˜ë©´ ì‚­ì œ"""
    keys = [
        "HF_HOME", "TRANSFORMERS_CACHE", "HF_DATASETS_CACHE",
        "XDG_CACHE_HOME", "UNSLOTH_CACHE_DIR", "TORCHINDUCTOR_CACHE_DIR",
    ]
    tmpdir = tempfile.mkdtemp(prefix="ft_cache_")
    old = {k: os.environ.get(k) for k in keys}
    try:
        for k in keys:
            os.environ[k] = tmpdir
        yield
    finally:
        for k, v in old.items():
            if v is None:
                os.environ.pop(k, None)
            else:
                os.environ[k] = v
        shutil.rmtree(tmpdir, ignore_errors=True)

# ===== Progress interval (seconds) =====
FT_PROGRESS_INTERVAL_SEC = int(os.getenv("FT_PROGRESS_INTERVAL_SEC", "2"))
# ===== Heartbeat timeout (seconds) for liveness detection =====
FT_HEARTBEAT_TIMEOUT_SEC = int(os.getenv("FT_HEARTBEAT_TIMEOUT_SEC", "300"))
# ===== OOM retry limit =====
MAX_OOM_RETRIES = int(os.getenv("FT_MAX_OOM_RETRIES", "1"))

# ===== Paths =====
BASE_BACKEND = Path(os.getenv("COREIQ_BACKEND_ROOT", str(Path(__file__).resolve().parents[2])))  # backend/
STORAGE_MODEL_ROOT = os.getenv("STORAGE_MODEL_ROOT", str(BASE_BACKEND / "storage" / "models"))
TRAIN_DATA_ROOT   = os.getenv("TRAIN_DATA_ROOT", str(BASE_BACKEND / "storage" / "train_data"))

# ===== SQLAlchemy ORM (Session) =====
from sqlalchemy import create_engine, select, func
from sqlalchemy.orm import sessionmaker
from storage.db_models import (
    LlmModel, FineTuneDataset, FineTuneJob as ORMJob, FineTunedModel
)

# DB_URL ì œê±° ë° get_session ì‚¬ìš©ìœ¼ë¡œ ëŒ€ì²´ë¨

# ---- Portable path helpers ----
def _to_rel(p: str) -> str:
    """`p`ë¥¼ backend ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜(ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜)."""
    try:
        return os.path.relpath(p, BASE_BACKEND)
    except Exception:
        return p

def _to_service_rel(p: str) -> str:
    """
    ì–´ë–¤ ê²½ë¡œë“  ìµœì¢…ì ìœ¼ë¡œ './service/<...>' í˜•íƒœë¡œ í‘œì¤€í™”.
    ì˜ˆ) /.../backend/storage/models/llm/Qwen3-8B  â†’ ./service/storage/models/llm/Qwen3-8B
        storage/models/llm/Qwen3-8B               â†’ ./service/storage/models/llm/Qwen3-8B
        ./service/storage/models/llm/Qwen3-8B     â†’ ê·¸ëŒ€ë¡œ ìœ ì§€
    """
    # ì ˆëŒ€ê²½ë¡œë©´ backend ê¸°ì¤€ ìƒëŒ€ê²½ë¡œë¡œ
    if os.path.isabs(p):
        p = os.path.relpath(p, BASE_BACKEND)
    s = p.replace("\\", "/").lstrip("./")
    if not s.startswith("service/"):
        s = f"service/{s}"
    # ì¤‘ë³µ ìŠ¬ë˜ì‹œ ì •ë¦¬
    while "//" in s:
        s = s.replace("//", "/")
    return f"./{s}"

# ===== Helpers: path resolve =====
def _resolve_model_dir(name_or_path: str) -> str:
    """Resolve a local model directory for finetuning.
    Priority: DB.llm_models.model_path (by exact name, then base-name) â†’ STORAGE_MODEL_ROOT/name.
    ì¸í„°ë„· ë‹¤ìš´ë¡œë“œëŠ” ì‹œë„í•˜ì§€ ì•ŠìŒ.
    """
    if os.path.isabs(name_or_path):
        return name_or_path

    # 1) DBì—ì„œ llm_models í…Œì´ë¸” ì¡°íšŒ
    try:
        with get_session() as s:
            # ì •í™•í•œ ì´ë¦„ìœ¼ë¡œ ë¨¼ì € ì°¾ê¸°
            stmt = select(LlmModel).where(LlmModel.name == name_or_path)
            model = s.execute(stmt).scalars().first()

            if not model:
                # ì¹´í…Œê³ ë¦¬ ì ‘ë¯¸ì‚¬ ì œê±° í›„ ë‹¤ì‹œ ì°¾ê¸°
                def _strip_cat(n: str) -> str:
                    for suf in ("-qna", "-doc_gen", "-summary"):
                        if n.endswith(suf):
                            return n[: -len(suf)]
                    return n

                base_name = _strip_cat(name_or_path)
                if base_name != name_or_path:
                    stmt = select(LlmModel).where(LlmModel.name == base_name)
                    model = s.execute(stmt).scalars().first()

            if model and model.model_path:
                p = model.model_path
                if os.path.isabs(p):
                    return p
                # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° STORAGE_MODEL_ROOT ê¸°ì¤€ìœ¼ë¡œ í•´ì„
                cand = os.path.join(STORAGE_MODEL_ROOT, p)
                if os.path.isdir(cand):
                    return cand
    except Exception as e:
        logger.warning(f"DB lookup failed for model {name_or_path}: {e}")

    # 2) Fallback to storage root
    return os.path.join(STORAGE_MODEL_ROOT, name_or_path)

def _has_model_signature(dir_path: str) -> bool:
    if not os.path.isdir(dir_path):
        return False
    sigs = [
        "config.json",
        "model.safetensors",
        "pytorch_model.bin",
        "generation_config.json",
    ]
    return any(os.path.isfile(os.path.join(dir_path, s)) for s in sigs)

def _resolve_train_path(p: str) -> str:
    if os.path.isabs(p):
        return p
    cand = os.path.join(TRAIN_DATA_ROOT, p)
    if os.path.isfile(cand):
        return cand
    try:
        for root, _, files in os.walk(TRAIN_DATA_ROOT):
            if p in files:
                return os.path.join(root, p)
    except Exception:
        pass
    return os.path.abspath(p)

# ===== Helpers: detect MXFP4 / gpt-oss =====
def _looks_like_mxfp4_model(dir_or_name: str) -> bool:
    name = (dir_or_name or "").lower()
    if "gpt-oss" in name:
        return True
    # ë¡œì»¬ í´ë”ì¼ ê²½ìš° configì—ì„œ íŒíŠ¸ ì°¾ê¸°
    try:
        cand = os.path.join(dir_or_name, "config.json")
        if os.path.isfile(cand):
            with open(cand, "r", encoding="utf-8") as f:
                cfg = json.load(f)
            txt = json.dumps(cfg).lower()
            if "mxfp4" in txt or "mx" in txt:
                return True
    except Exception:
        pass
    # ì–‘ìí™” ì„¤ì • íŒŒì¼ ì¼€ì´ìŠ¤
    for q in ("quantization_config.json", "quantize_config.json"):
        try:
            cand = os.path.join(dir_or_name, q)
            if os.path.isfile(cand):
                with open(cand, "r", encoding="utf-8") as f:
                    if "mxfp4" in f.read().lower():
                        return True
        except Exception:
            pass
    return False

# ===== Schemas =====
class FineTuneRequest(BaseModel):
    # === ê³µí†µ íƒœê·¸(í•„ìˆ˜) ===
    category: str = Field(..., description="qna | doc_gen | summary")
    subcategory: Optional[str] = Field(None, description="ì„¸ë¶€ í…ŒìŠ¤í¬. í˜„ì¬ ì£¼ë¡œ doc_genì—ì„œ ì‚¬ìš©")

    baseModelName: str
    saveModelName: str
    systemPrompt: str
    batchSize: int = 1
    epochs: int = 3
    learningRate: float = 2e-4
    overfittingPrevention: bool = True
    trainSetFile: str
    gradientAccumulationSteps: int = 16
    quantizationBits: Optional[int] = Field(
        default=None, description="QLORA ì „ìš©: ì–‘ìí™” ë¹„íŠ¸ (4 ë˜ëŠ” 8)",
    )
    tuningType: Optional[str] = Field(
        default="QLORA",
        description="íŒŒì¸íŠœë‹ ë°©ì‹: LORA | QLORA | FULL",
        pattern="^(LORA|QLORA|FULL)$",
    )
    
    @field_validator("tuningType", mode="before")
    @classmethod
    def _v_tuning_type_strip(cls, v):
        """tuningType ê°’ì˜ ì•ë’¤ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤."""
        if v is None:
            return None
        if isinstance(v, str):
            return v.strip()
        return v
    startAt: Optional[str] = Field(
        default=None, description="ì˜ˆì•½ ì‹œì‘ ISO8601 (ì˜ˆ: 2025-09-19T13:00:00)"
    )
    startNow: bool = Field(
        default=False, description="ì¦‰ì‹œ ì‹¤í–‰ ì—¬ë¶€ (True: ë°”ë¡œ ì‹œì‘, False: ì˜ˆì•½ë§Œ ë“±ë¡)"
    )

    @field_validator("category")
    @classmethod
    def _v_category(cls, v: str) -> str:
        allowed = {"qna", "doc_gen", "summary"}
        vv = (v or "").strip().lower()
        if vv not in allowed:
            raise ValueError(f"category must be one of {sorted(allowed)}")
        return vv

    @field_validator("quantizationBits", mode="before")
    @classmethod
    def _v_qbits_empty_to_none(cls, v):
        """
        í¼ì—ì„œ ë¹ˆ ë¬¸ìì—´("")ë¡œ ë„˜ì–´ì˜¤ëŠ” quantizationBitsë¥¼ Noneìœ¼ë¡œ ì²˜ë¦¬.
        FULL/LORAì—ì„œëŠ” quantizationBitsë¥¼ ë¹„ì›Œë„ ë˜ë„ë¡ í—ˆìš©í•˜ê³ ,
        QLORAì¸ ê²½ìš°ì—ë§Œ ì•„ë˜ validator/model_validatorì—ì„œ 4 ë˜ëŠ” 8ì„ ê°•ì œí•œë‹¤.
        """
        if v in ("", None):
            return None
        return v

    @field_validator("quantizationBits")
    @classmethod
    def _v_qbits_range(cls, v: Optional[int]):
        if v is None:
            return v
        if v not in (4, 8):
            raise ValueError("quantizationBits must be 4 or 8 when provided")
        return v

    @model_validator(mode="after")
    def _v_qbits_required_for_qlora(self):
        if (self.tuningType or "").upper() == "QLORA":
            if self.quantizationBits not in (4, 8):
                raise ValueError("QLORA requires quantizationBits=4 or 8")
        return self

@dataclass
class FineTuneJob:
    job_id: str
    category: str
    request: Dict[str, Any]
    status: str = "queued"  # queued | running | succeeded | failed

# ===== Common utils =====
def _now_local_str() -> str:
    """í˜„ì¬ ì‹œê°„ì„ KSTë¡œ ë°˜í™˜"""
    kst = timezone(timedelta(hours=9))
    return datetime.now(kst).strftime("%Y-%m-%d %H:%M:%S")

def _now_utc() -> datetime:
    """í˜„ì¬ ì‹œê°„ì„ UTCë¡œ ë°˜í™˜"""
    return datetime.now(timezone.utc)

def _to_kst(utc_dt: datetime) -> datetime:
    """UTC datetimeì„ KSTë¡œ ë³€í™˜"""
    if utc_dt.tzinfo is None:
        utc_dt = utc_dt.replace(tzinfo=timezone.utc)
    kst = timezone(timedelta(hours=9))
    return utc_dt.astimezone(kst)

def _ensure_output_dir(model_name: str) -> str:
    try:
        os.makedirs(STORAGE_MODEL_ROOT, exist_ok=True)
    except PermissionError as e:
        raise InternalServerError(f"permission denied creating model root '{STORAGE_MODEL_ROOT}': {e}")
    except OSError as e:
        try:
            if getattr(e, "errno", None) == 13:
                raise InternalServerError(f"permission denied creating model root '{STORAGE_MODEL_ROOT}': {e}")
        except Exception:
            pass
        raise

    out_dir = os.path.join(STORAGE_MODEL_ROOT, model_name)
    try:
        os.makedirs(out_dir, exist_ok=True)
    except PermissionError as e:
        raise InternalServerError(f"permission denied creating output dir '{out_dir}': {e}")
    except OSError as e:
        try:
            if getattr(e, "errno", None) == 13:
                raise InternalServerError(f"permission denied creating output dir '{out_dir}': {e}")
        except Exception:
            pass
        raise
    cfg_path = os.path.join(out_dir, "config.json")
    if not os.path.isfile(cfg_path):
        try:
            with open(cfg_path, "w", encoding="utf-8") as f:
                json.dump({"created_at": _now_utc().isoformat()}, f, ensure_ascii=False)
        except Exception:
            logger.exception(f"failed to write config.json inside {out_dir}")
    return out_dir

def _ensure_lora_marker(out_dir: str, tuning_type: str):
    if tuning_type.upper() in ("LORA", "QLORA"):
        marker = os.path.join(out_dir, "adapter_config.json")
        if not os.path.isfile(marker):
            try:
                with open(marker, "w", encoding="utf-8") as f:
                    json.dump({"peft_type": "LORA", "tuning": tuning_type.upper()}, f, ensure_ascii=False)
            except Exception:
                logger.exception(f"failed to create LoRA marker {marker}")

def _append_log(log_path: str, line: str):
    try:
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(line.rstrip("\n") + "\n")
    except Exception:
        # Log but do not interrupt main flow
        logger.exception(f"failed to append log to {log_path}")

# ----- Error helper -----
def _write_error(out_dir: str, message: str):
    """Write error message to a dedicated error.txt inside output dir."""
    try:
        os.makedirs(out_dir, exist_ok=True)
        err_path = os.path.join(out_dir, "error.txt")
        with open(err_path, "a", encoding="utf-8") as f:
            ts = _now_utc().isoformat()
            f.write(f"[{ts}] {message}\n")
    except Exception:
        logger.exception(f"failed to write error file under {out_dir}")


# ===== DB ops =====
def _insert_dataset_if_needed(conn, path: str, category: str) -> int:
    # ==== ORM ë²„ì „ ====
    # conn ì¸ìëŠ” í˜¸í™˜ì„± ìœ ì§€ìš©ìœ¼ë¡œ ë‚¨ê²¨ë‘ì§€ë§Œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    rel_path = _to_rel(path)
    with get_session() as s:
        stmt = select(FineTuneDataset).where(FineTuneDataset.path == rel_path)
        exist = s.execute(stmt).scalars().first()
        if exist:
            return int(exist.id)
        row = FineTuneDataset(
            name=os.path.basename(path),
            category=category,
            path=rel_path,
            record_count=None,
        )
        s.add(row)
        s.commit()
        s.refresh(row)
        return int(row.id)

def _insert_job(conn, category: str, req: FineTuneRequest, job_id: str, save_name_with_suffix: str, dataset_id: int,
                initial_status: str = "queued", scheduled_at: Optional[str] = None) -> int:
    # ==== ORM ë²„ì „ ====
    reserve_now = _now_local_str()
    train_path = _resolve_train_path(req.trainSetFile)
    train_rel_path = _to_rel(train_path)
    hyper = {
        "systemPrompt": req.systemPrompt,
        "batchSize": req.batchSize,
        "epochs": req.epochs,
        "learningRate": req.learningRate,
        "overfittingPrevention": req.overfittingPrevention,
        "tuningType": (req.tuningType or "QLORA").upper(),
        "baseModelName": req.baseModelName,
        "saveModelName": save_name_with_suffix,
        "trainSetFile": train_rel_path,
        "reserveDate": reserve_now,
        "category": category,
        "subcategory": (req.subcategory or None),
        "gradientAccumulationSteps": req.gradientAccumulationSteps,
        "quantizationBits": req.quantizationBits,
    }
    metrics = {"hyperparameters": hyper}
    if scheduled_at:
        metrics["scheduledAt"] = scheduled_at
        metrics["learningProgress"] = 0

    with get_session() as s:
        row = ORMJob(
            provider_job_id=job_id,
            dataset_id=dataset_id,
            status=initial_status,
            started_at=None,  # ì‹¤ì œ ì‹œì‘ ì‹œì ì— ì„¤ì •
            metrics=json.dumps(metrics, ensure_ascii=False),
        )
        s.add(row)
        s.commit()
        s.refresh(row)
        return int(row.id)

# _update_job_statusëŠ” ì´ì œ Repositoryë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ì§ì ‘ êµ¬í˜„
# ê¸°ì¡´ ë¡œì§ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ë˜í¼ í•¨ìˆ˜ë¡œ ìœ ì§€í•˜ë˜, repository í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
def _update_job_status(conn, job_id: str, status: str, progress: int | None = None, rough: int | None = None, extras: dict | None = None, _retries: int = 3):
    """
    repository/llm_finetuning.pyì˜ update_job_statusë¥¼ í˜¸ì¶œ
    conn ì¸ìëŠ” ë¬´ì‹œë¨ (repositoryì—ì„œ get_session ì‚¬ìš©)
    """
    try:
        update_job_status(job_id, status, progress, extras, rough)
        
        # Additional logging
        out_dir = _resolve_out_dir_by_job(job_id)
        if out_dir:
            log_path = os.path.join(out_dir, "train.log")
            msg = f"status={status} progress={progress} rough={rough} extras={extras or {}}"
            _append_log(log_path, f"[{_now_utc().isoformat()}] {msg}")
            
    except Exception as e:
        logger.error(f"Failed to update job status: {e}")

def _resolve_out_dir_by_job(job_id: str) -> Optional[str]:
    # ORM ë²„ì „
    with get_session() as s:
        stmt = select(ORMJob).where(ORMJob.provider_job_id == job_id)
        job = s.execute(stmt).scalars().first()
        
        if not job:
            return None
            
        save_name = None
        if job.metrics:
            try:
                mt = json.loads(job.metrics) or {}
                hp = mt.get("hyperparameters") or {}
                save_name = hp.get("saveModelName")
            except Exception:
                pass
        
        if not save_name:
            return None
            
        return os.path.join(STORAGE_MODEL_ROOT, save_name)


# ===== Training (inline, real) =====
def _run_training_inline(job: FineTuneJob, save_name_with_suffix: str):
    """
    Unsloth gpt-oss(20B) ë…¸íŠ¸ë¶ íë¦„ì„ ë°˜ì˜í•œ ê²½ëŸ‰/ì•ˆì • íŒŒì´í”„ë¼ì¸.
    """
    import gc
    try:
        # _update_job_status í˜¸ì¶œ (connì€ Noneìœ¼ë¡œ ì „ë‹¬í•´ë„ ë¨, ë‚´ë¶€ì—ì„œ ë¬´ì‹œ)
        _update_job_status(None, job.job_id, "running", progress=0)

        out_dir = _ensure_output_dir(save_name_with_suffix)
        tuning_type = (job.request.get("tuningType") or "QLORA").upper()
        if tuning_type in ("LORA", "QLORA"):
            _ensure_lora_marker(out_dir, tuning_type)
        log_path = os.path.join(out_dir, "train.log")
        try:
            with open(log_path, "w", encoding="utf-8") as _tmp:
                _tmp.write("")
        except Exception:
            pass
        _append_log(log_path, f"[{_now_utc().isoformat()}] job {job.job_id} started (INLINE)")
        logger.info(
            f"Fine-tuning started jobId={job.job_id} type={tuning_type} base={job.request.get('baseModelName')} "
            f"save={save_name_with_suffix} data={job.request.get('trainSetFile')}"
        )

        # âœ… ì„ì‹œ ìºì‹œ í´ë”
        tmpdir = tempfile.mkdtemp(prefix="ft_cache_")
        cache_keys = ["HF_HOME", "TRANSFORMERS_CACHE", "HF_DATASETS_CACHE", "XDG_CACHE_HOME", "UNSLOTH_CACHE_DIR", "TORCHINDUCTOR_CACHE_DIR"]
        old_cache = {k: os.environ.get(k) for k in cache_keys}
        for k in cache_keys:
            os.environ[k] = tmpdir

        # ===== Imports =====
        try:
            from unsloth import FastLanguageModel  # type: ignore
            import pandas as pd
            import torch
            from transformers import (
                AutoModelForCausalLM,
                AutoTokenizer,
                TrainingArguments,
                Trainer,
                BitsAndBytesConfig,
                TrainerCallback,
            )
        except Exception as e:
            _append_log(log_path, f"[{_now_utc().isoformat()}] import error: {e}")
            fail_job(job.job_id, f"import error: {e}")
            logger.error(f"Fine-tuning failed jobId={job.job_id} error=import error: {e}")
            return

        # ===== ë°ì´í„° ì ì¬/ì „ì²˜ë¦¬ =====
        system_prompt = job.request.get("systemPrompt") or "You are Qwen, a helpful assistant."
        def build_prompt(context: str, question: str) -> str:
            return f"{context.strip()}\n{system_prompt}\nQuestion: {question.strip()}"

        csv_path = _resolve_train_path(job.request.get("trainSetFile"))
        encodings_to_try = ["utf-8", "utf-8-sig", "cp949", "euc-kr", "latin1"]
        df = None
        for enc in encodings_to_try:
            try:
                df = pd.read_csv(csv_path, encoding=enc, dtype=str).fillna("")
                break
            except Exception:
                continue
        if df is None:
            try:
                import chardet
                with open(csv_path, "rb") as f:
                    raw = f.read(10000)
                enc = chardet.detect(raw).get("encoding") or "utf-8"
                df = pd.read_csv(csv_path, encoding=enc, dtype=str, on_bad_lines="skip").fillna("")
            except Exception as e:
                _append_log(log_path, f"[{_now_utc().isoformat()}] csv load failed: {e}")
                fail_job(job.job_id, f"csv load failed: {e}")
                logger.error(f"Fine-tuning failed jobId={job.job_id} error=csv load failed: {e}")
                return

        conversations = [{
            "conversations": [
                {"from": "user", "value": build_prompt(r.get("ChunkContext",""), r.get("Question",""))},
                {"from": "assistant", "value": r.get("Answer","")},
            ]
        } for _, r in df.iterrows()]

        # ===== 7:3 ê³ ì • split (random_state=42) =====
        total = len(conversations)
        eval_size = max(1, int(round(total * 0.3))) if total >= 2 else 0
        if eval_size > 0:
            import random as _R
            idx = list(range(total))
            rng = _R.Random(42)
            rng.shuffle(idx)
            eval_idx = set(idx[:eval_size])
            train_data = [conversations[i] for i in idx[eval_size:]]
            eval_data  = [conversations[i] for i in idx[:eval_size]]
        else:
            train_data, eval_data = conversations, []
        _append_log(log_path, f"[{_now_utc().isoformat()}] split: total={total} eval={eval_size} train={len(train_data)}")

        class RagDataset(torch.utils.data.Dataset):
            def __init__(self, data, tokenizer, max_len=4096):
                self.data = data
                self.tk = tokenizer
                self.max_len = max_len
            def __len__(self): return len(self.data)
            def __getitem__(self, i):
                dialog = self.data[i]["conversations"]
                messages = [
                    {"role": "system", "content": "You are Qwen, a helpful assistant."},
                    {"role": "user", "content": dialog[0]["value"]},
                    {"role": "assistant", "content": dialog[1]["value"]},
                ]
                full = self.tk.apply_chat_template(messages, tokenize=False)
                enc = self.tk(full, max_length=self.max_len, truncation=True, padding="max_length", return_tensors="pt")
                input_ids = enc.input_ids[0]
                assist = self.tk.apply_chat_template(messages[:-1], tokenize=False, add_generation_prompt=True)
                prefix_len = len(self.tk(assist).input_ids)
                labels = input_ids.clone()
                labels[:prefix_len] = -100
                return {"input_ids": input_ids, "attention_mask": enc.attention_mask[0], "labels": labels}

        base_folder = _resolve_model_dir(job.request.get("baseModelName"))
        if not _has_model_signature(base_folder):
            msg = f"base model not found: {base_folder}"
            _append_log(log_path, f"[{_now_utc().isoformat()}] {msg}")
            fail_job(job.job_id, msg)
            logger.error(f"Fine-tuning failed jobId={job.job_id} error={msg}")
            return

        model_path = base_folder
        output_dir = os.path.join(STORAGE_MODEL_ROOT, save_name_with_suffix)
        is_mxfp4 = _looks_like_mxfp4_model(model_path) or _looks_like_mxfp4_model(job.request.get("baseModelName"))

        # ===== ëª¨ë¸ ë¡œë”© ì „ ë©”ëª¨ë¦¬ ì •ë¦¬ =====
        # _clear_gpu_memory()

        # ===== ëª¨ë¸/í† í¬ë‚˜ì´ì € ë¡œë“œ =====
        # gpt-oss(MXFP4) â†’ Unsloth
        if tuning_type == "QLORA" and is_mxfp4:
            max_len = int(job.request.get("max_len", 3072))  # ğŸ’¡ ê¸°ë³¸ 3072ë¡œ ì‚´ì§ ë‚®ì¶° OOM ì˜ˆë°©
            # ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë°©ì§€ë¥¼ ìœ„í•´ ë¡œë”© ì „ ë©”ëª¨ë¦¬ ì •ë¦¬
            # _clear_gpu_memory()
            model, tokenizer = FastLanguageModel.from_pretrained(
                model_name=model_path,
                dtype=None,                    # H100 â†’ bf16 ìë™
                max_seq_length=max_len,
                load_in_4bit=True,
                full_finetuning=False,
                trust_remote_code=True,
                local_files_only=True,
            )
            # ë¡œë”© í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
            # _clear_gpu_memory()
            # Unsloth ëª¨ë²”ì‚¬ë¡€: í•™ìŠµ ìµœì í™” í™œì„±í™”
            try:
                model = FastLanguageModel.for_training(model)  # ì¼ë¶€ ë²„ì „ì—ì„  in-place. ë°˜í™˜ê°’ í˜¸í™˜.
            except Exception:
                pass
            try:
                model = FastLanguageModel.get_peft_model(
                    model,
                    r=64,
                    lora_alpha=16,
                    lora_dropout=0.05,
                    bias="none",
                )
            except Exception:
                from peft import LoraConfig, get_peft_model  # type: ignore
                lora_cfg = LoraConfig(r=64, lora_alpha=16, lora_dropout=0.05, bias="none", task_type="CAUSAL_LM")
                model = get_peft_model(model, lora_cfg)

        elif tuning_type == "QLORA":
            # ì¼ë°˜ QLORA
            from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training  # type: ignore
            bnb = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_use_double_quant=True,
                bnb_4bit_quant_type="nf4",
                bnb_4bit_compute_dtype=torch.bfloat16,
            )
            tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, local_files_only=True)
            if tokenizer.pad_token_id is None:
                if getattr(tokenizer, "eos_token_id", None) is not None:
                    tokenizer.pad_token_id = tokenizer.eos_token_id
                else:
                    tokenizer.add_special_tokens({"pad_token": "<|pad|>"})
                    tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids("<|pad|>")
            # ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë°©ì§€ë¥¼ ìœ„í•´ ë¡œë”© ì „ ë©”ëª¨ë¦¬ ì •ë¦¬
            # _clear_gpu_memory()
            model = AutoModelForCausalLM.from_pretrained(
                model_path,
                trust_remote_code=True,
                device_map="auto",
                quantization_config=bnb,
                local_files_only=True,
            )
            model.gradient_checkpointing_enable()
            model = prepare_model_for_kbit_training(model)
            # ë¡œë”© í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
            # _clear_gpu_memory()
            lora_targets = [
                "q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj",
                "down_proj","w1","w2","c_proj","c_attn"
            ]
            from itertools import chain
            target_modules = sorted({
                n.split(".")[-1]
                for n, _ in model.named_modules()
                if any(k in n for k in lora_targets)
            })
            lora_cfg = LoraConfig(
                r=64, lora_alpha=16, target_modules=(target_modules or None),
                lora_dropout=0.05, bias="none", task_type="CAUSAL_LM",
            )
            model = get_peft_model(model, lora_cfg)
            max_len = int(job.request.get("max_len", 4096))
        elif tuning_type == "LORA":
            from peft import LoraConfig, get_peft_model  # type: ignore
            tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, local_files_only=True)
            if tokenizer.pad_token_id is None:
                if getattr(tokenizer, "eos_token_id", None) is not None:
                    tokenizer.pad_token_id = tokenizer.eos_token_id
                else:
                    tokenizer.add_special_tokens({"pad_token": "<|pad|>"})
                    tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids("<|pad|>")
            # ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë°©ì§€ë¥¼ ìœ„í•´ ë¡œë”© ì „ ë©”ëª¨ë¦¬ ì •ë¦¬
            # _clear_gpu_memory()
            model = AutoModelForCausalLM.from_pretrained(
                model_path,
                trust_remote_code=True,
                device_map="auto",
                torch_dtype=torch.bfloat16,
                local_files_only=True,
            )
            model.gradient_checkpointing_enable()
            # ë¡œë”© í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
            # _clear_gpu_memory()
            targets = [
                "q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj",
                "down_proj","w1","w2","c_proj","c_attn"
            ]
            target_modules = sorted({ n.split(".")[-1] for n,_ in model.named_modules() if any(k in n for k in targets) })
            lora_cfg = LoraConfig(r=64, lora_alpha=16, target_modules=(target_modules or None), lora_dropout=0.05, bias="none", task_type="CAUSAL_LM")
            model = get_peft_model(model, lora_cfg)
            max_len = int(job.request.get("max_len", 4096))
        else:  # FULL
            # ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë°©ì§€ë¥¼ ìœ„í•´ ë¡œë”© ì „ ë©”ëª¨ë¦¬ ì •ë¦¬
            # _clear_gpu_memory()
            tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, local_files_only=True)
            if tokenizer.pad_token_id is None:
                if getattr(tokenizer, "eos_token_id", None) is not None:
                    tokenizer.pad_token_id = tokenizer.eos_token_id
                else:
                    tokenizer.add_special_tokens({"pad_token": "<|pad|>"})
                    tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids("<|pad|>")
            model = AutoModelForCausalLM.from_pretrained(
                model_path, trust_remote_code=True, device_map="auto", torch_dtype=torch.bfloat16, local_files_only=True,
            )
            model.gradient_checkpointing_enable()
            for p in model.parameters(): p.requires_grad = True
            # ë¡œë”© í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
            # _clear_gpu_memory()
            # FULL íŒŒì¸íŠœë‹ì€ ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ê¸°ë³¸ max_lenì„ ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì •
            max_len = int(job.request.get("max_len", 2048))  # ê¸°ë³¸ê°’ì„ 4096ì—ì„œ 2048ë¡œ ê°ì†Œ

        # ===== ë°ì´í„°ì…‹ ìƒì„± =====
        train_ds = RagDataset(train_data, tokenizer, max_len=max_len)
        eval_ds  = RagDataset(eval_data,  tokenizer, max_len=max_len) if eval_size > 0 else None
        use_eval = eval_ds is not None and len(eval_data) > 0

        # ===== TrainingArguments (ë²„ì „ í˜¸í™˜ í‚¤ ìë™ ë§¤í•‘) =====
        from inspect import signature as _sig
        def _supported_args(cls): return set(_sig(cls.__init__).parameters.keys())
        def _put_kw(supported: set, kw: dict, key: str, value, *aliases: str):
            for k in (key, *aliases):
                if k in supported:
                    kw[k] = value
                    return k
            return None

        optim_name = os.getenv("FT_OPTIM", ("adamw_torch" if tuning_type in ("FULL","LORA") else "paged_adamw_8bit"))
        save_strategy_val = "epoch" if use_eval else "no"
        eval_strategy_val = "epoch" if use_eval else "no"

        _ta = dict(
            output_dir=output_dir,
            num_train_epochs=job.request.get("epochs", 3),
            per_device_train_batch_size=job.request.get("batchSize", 1),
            gradient_accumulation_steps=job.request.get("gradientAccumulationSteps", 8),
            learning_rate=job.request.get("learningRate", 2e-4),
            bf16=True,
            logging_steps=10,
            report_to="none",
            optim=optim_name,
            seed=42,
            data_seed=42,
            save_total_limit=2,
            warmup_ratio=0.05,
        )
        sup = _supported_args(TrainingArguments)
        _put_kw(sup, _ta, "save_strategy", save_strategy_val)
        _put_kw(sup, _ta, "evaluation_strategy", eval_strategy_val, "eval_strategy")
        _put_kw(sup, _ta, "gradient_checkpointing", True)
        _put_kw(sup, _ta, "lr_scheduler_type", "cosine")
        _put_kw(sup, _ta, "save_safetensors", True)
        if use_eval:
            _put_kw(sup, _ta, "load_best_model_at_end", True)
            _put_kw(sup, _ta, "metric_for_best_model", "eval_loss")
            _put_kw(sup, _ta, "greater_is_better", False)
            _put_kw(sup, _ta, "per_device_eval_batch_size", max(1, job.request.get("batchSize", 1)))

        training_args = TrainingArguments(**_ta)

        # ===== ì½œë°± =====
        class ProgressCallback(TrainerCallback):
            def __init__(self, job_id: str, every_steps: int | None = None):
                self.job_id = job_id
                self.every_steps = every_steps if every_steps else max(1, int(os.getenv("FT_PROGRESS_EVERY_STEPS", "1")))
                self.total_steps = None
            def on_train_begin(self, args, state, control, **kw):
                _update_job_status(None, self.job_id, "running", progress=0)
            def on_train_begin_dataloader(self, args, state, control, **kw):
                try:
                    if state.max_steps and state.max_steps > 0:
                        self.total_steps = int(state.max_steps)
                except Exception:
                    pass
            def on_step_end(self, args, state, control, **kw):
                try:
                    total = self.total_steps or (state.max_steps or 0)
                    if not total or state.global_step % self.every_steps != 0: return
                    pct = int(min(100, max(0, round((state.global_step/total)*100))))
                    _update_job_status(None, self.job_id, "running", progress=pct)
                except Exception:
                    pass
            def on_train_end(self, args, state, control, **kw):
                _update_job_status(None, self.job_id, "running", progress=100)

        class LogCallback(TrainerCallback):
            def on_log(self, args, state, control, logs=None, **kw):
                if logs and "loss" in logs:
                    _append_log(log_path, f"[{_now_utc().isoformat()}] step={state.global_step} loss={logs['loss']}")

        def _build_trainer():
            return Trainer(
                model=model,
                args=training_args,
                train_dataset=train_ds,
                eval_dataset=eval_ds,
                tokenizer=tokenizer,  # FutureWarningì€ ë¬´ì‹œ ê°€ëŠ¥ (ì¶”í›„ processing_classë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜)
                callbacks=[ProgressCallback(job.job_id), LogCallback()],
            )

        trainer = _build_trainer()

        # ===== í•™ìŠµ + OOM ì„¸ì´í”„ ì¬ì‹œë„ =====
        import math
        try:
            _append_log(log_path, f"[{_now_utc().isoformat()}] training started...")
            trainer.train()
        except RuntimeError as re:
            if "out of memory" in str(re).lower():
                # ğŸ”» ë°°ì¹˜/ì‹œí€€ìŠ¤ ë™ì‹œ ì¶•ì†Œ + **ì´ì „ Trainer/ê·¸ë˜í”„ ì™„ì „ ì •ë¦¬**
                old_bs = training_args.per_device_train_batch_size
                new_bs = max(1, old_bs // 2)
                new_len = max(1024, int(max_len * 0.75))
                _append_log(log_path, f"[{_now_utc().isoformat()}] OOM â†’ retry with batch={new_bs}, max_len={new_len}")
                # ë©”ëª¨ë¦¬ í•´ì œ
                try:
                    del trainer
                    # _clear_gpu_memory()
                except Exception:
                    pass
                # ì¬êµ¬ì„±
                training_args.per_device_train_batch_size = new_bs
                train_ds = RagDataset(train_data, tokenizer, max_len=new_len)
                eval_ds  = RagDataset(eval_data,  tokenizer, max_len=new_len) if use_eval else None
                trainer = Trainer(
                    model=model,
                    args=training_args,
                    train_dataset=train_ds,
                    eval_dataset=eval_ds,
                    tokenizer=tokenizer,
                    callbacks=[ProgressCallback(job.job_id), LogCallback()],
                )
                trainer.train()
            else:
                raise

        # ===== ê°„ë‹¨ ROUGE-1 (ì˜µì…”ë„) =====
        def _rouge1_f1(ref: str, cand: str) -> float:
            rw, cw = ref.split(), cand.split()
            if not rw or not cw: return 0.0
            m = sum(1 for w in cw if w in rw)
            p = m/len(cw) if cw else 0.0
            r = m/len(rw) if rw else 0.0
            return 0.0 if (p+r)==0 else 2*(p*r)/(p+r)

        final_rouge = None
        if use_eval:
            model.eval()
            preds, refs = [], []
            device = _get_model_device(model)
            for item in eval_ds:
                inp_ids = item["input_ids"].unsqueeze(0).to(device)
                attn = item["attention_mask"].unsqueeze(0).to(device)
                try:
                    with torch.inference_mode():
                        out_ids = model.generate(
                            inp_ids,
                            attention_mask=attn,
                            max_new_tokens=128,
                            do_sample=False,
                        )[0]
                except Exception:
                    continue
                preds.append(tokenizer.decode(out_ids, skip_special_tokens=True))
                ref_ids = item["labels"]
                ref_ids = torch.where(ref_ids == -100, torch.tensor(tokenizer.pad_token_id), ref_ids)
                refs.append(tokenizer.decode(ref_ids, skip_special_tokens=True))
            scores = [_rouge1_f1(r, p) for r, p in zip(refs, preds)]
            if scores: final_rouge = sum(scores) / len(scores)
            _update_job_status(None, job.job_id, "running", rough=int((final_rouge or 0)*100), extras={"rouge1F1": final_rouge})

        # ===== ì €ì¥ =====
        def _save_stage(stage: str, pct: int):
            _append_log(log_path, f"[{_now_utc().isoformat()}] save:{stage} {pct}%")
            _update_job_status(None, job.job_id, "running", extras={"saveStage": stage, "saveProgress": pct})

        _save_stage("start", 5)
        _append_log(log_path, f"[{_now_utc().isoformat()}] saving model...")

        if tuning_type in ("LORA", "QLORA"):
            try:
                model.save_pretrained(output_dir)     # ì–´ëŒ‘í„°ë§Œ ì €ì¥
                _save_stage("adapter", 70)
                tokenizer.save_pretrained(output_dir)
                _save_stage("tokenizer", 90)
                _append_log(log_path, f"[{_now_utc().isoformat()}] saved adapters â†’ {output_dir}")
            except Exception as e:
                trainer.save_model(output_dir)
                _save_stage("model", 70)
                tokenizer.save_pretrained(output_dir)
                _save_stage("tokenizer", 90)
                _append_log(log_path, f"[{_now_utc().isoformat()}] fallback save (trainer.save_model): {e}")
            # MXFP4 ë³‘í•© ì €ì¥ì€ ì„ íƒ(ê¸°ë³¸ ë¹„í™œì„±)
            if is_mxfp4 and os.getenv("FT_UNSLOTH_MERGE_SAVE","0") == "1":
                try:
                    model.save_pretrained_merged(output_dir, tokenizer, save_method="mxfp4")
                    _append_log(log_path, f"[{_now_utc().isoformat()}] merged MXFP4 saved â†’ {output_dir}")
                except Exception as e:
                    _append_log(log_path, f"[{_now_utc().isoformat()}] MXFP4 merge save failed: {e}, adapters only.")
        else:
            trainer.save_model(output_dir)
            _save_stage("model", 70)
            tokenizer.save_pretrained(output_dir)
            _save_stage("tokenizer", 90)

        _save_stage("done", 100)

        finish_job_success(
            job.job_id, save_name_with_suffix, job.category, tuning_type, final_rouge, subcategory=job.request.get("subcategory"),
        )
        logger.info(f"Fine-tuning succeeded jobId={job.job_id} save={save_name_with_suffix} type={tuning_type}")
        _append_log(log_path, f"[{_now_utc().isoformat()}] job {job.job_id} succeeded")

    except Exception as e:
        logger.error(f"Fine-tuning failed jobId={job.job_id} error={e}")
        try:
            _append_log(os.path.join(STORAGE_MODEL_ROOT, save_name_with_suffix, "train.log"), f"[{_now_utc().isoformat()}] error: {e}")
        except Exception:
            pass
        
        fail_job(job.job_id, str(e))
        
    finally:
        # ìì› ì •ë¦¬
        try:
            del trainer
        except Exception:
            pass
        try:
            del model, tokenizer
        except Exception:
            pass
        try:
            import torch
            gc.collect()
            if hasattr(torch, "cuda") and torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.ipc_collect()
        except Exception:
            pass
        try:
            for k, v in old_cache.items():
                if v is None: os.environ.pop(k, None)
                else: os.environ[k] = v
            shutil.rmtree(tmpdir, ignore_errors=True)
        except Exception:
            pass
        # conn.close()  <-- ì œê±°ë¨

# ===== Public APIs =====
def _log_to_save_name(save_name_with_suffix: str, message: str):
    try:
        out_dir = _ensure_output_dir(save_name_with_suffix)
        log_path = os.path.join(out_dir, "train.log")
        _append_log(log_path, f"[{_now_utc().isoformat()}] {message}")
    except Exception:
        pass

def start_fine_tuning(category: str, body: FineTuneRequest) -> Dict[str, Any]:
    # startNowì™€ startAt ë™ì‹œ ì§€ì • ë°©ì§€
    if body.startNow and body.startAt:
        raise BadRequestError("startNowì™€ startAtì€ ë™ì‹œì— ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ)")

    # body.categoryë¥¼ ìµœì¢… ì‹ ë¢°(í•˜ìœ„í˜¸í™˜ì„ ìœ„í•´ ì¸ìˆ˜ categoryëŠ” fallback)
    category = (body.category or category).lower()
    suffix = (body.tuningType or "QLORA").upper()
    # ì¹´í…Œê³ ë¦¬ê¹Œì§€ í¬í•¨í•˜ì—¬ ì €ì¥ í´ë”/ëª¨ë¸ëª…ì„ êµ¬ë¶„ (ì˜ˆ: name-QLORA-qna)
    save_name_with_suffix = f"{body.saveModelName}-{suffix}-{category}"
    _ensure_output_dir(save_name_with_suffix)

    # ì¤‘ë³µ ì‹¤í–‰ ì°¨ë‹¨ (ë½ íŒŒì¼)
    import fcntl
    out_dir = _ensure_output_dir(save_name_with_suffix)
    lock_path = os.path.join(out_dir, ".run.lock")
    lock_f = open(lock_path, "w")
    try:
        fcntl.flock(lock_f, fcntl.LOCK_EX | fcntl.LOCK_NB)
        lock_f.write(f"locked at {_now_utc().isoformat()}\n")
        lock_f.flush()
    except BlockingIOError:
        lock_f.close()
        raise BadRequestError(f"another fine-tune is already running for {save_name_with_suffix}")

    base_dir = _resolve_model_dir(body.baseModelName)
    if not _has_model_signature(base_dir):
        msg = f"base model not found: {base_dir}"
        logger.error(msg)
        _log_to_save_name(save_name_with_suffix, msg)
        raise BadRequestError(msg)

    job_id = f"ft-job-{uuid.uuid4().hex[:12]}"

    try:
        train_path = _resolve_train_path(body.trainSetFile)
        dataset_id = _insert_dataset_if_needed(None, train_path, category) # conn ì¸ì None ì „ë‹¬
        # ì˜ˆì•½ ì‹œê°„ íŒŒì‹±
        scheduled_at_iso = None
        delay_sec = 0.0
        if body.startAt:
            try:
                scheduled_dt = datetime.fromisoformat(body.startAt)
                # timezone ì •ë³´ê°€ ì—†ìœ¼ë©´ KSTë¡œ ê°€ì •
                if scheduled_dt.tzinfo is None:
                    kst = timezone(timedelta(hours=9))
                    scheduled_dt = scheduled_dt.replace(tzinfo=kst)
                now_dt = _now_utc()
                delta = (scheduled_dt - now_dt).total_seconds()
                if delta > 1.0:
                    delay_sec = float(delta)
                    scheduled_at_iso = scheduled_dt.isoformat()
            except Exception:
                scheduled_at_iso = None
                delay_sec = 0.0

        _insert_job(
            None, category, body, job_id, save_name_with_suffix, dataset_id, # conn ì¸ì None
            initial_status=("scheduled" if delay_sec > 1.0 else "queued"),
            scheduled_at=scheduled_at_iso,
        )
    except Exception as e:
        _log_to_save_name(save_name_with_suffix, f"db insert failed: {e}")
        logger.error(f"fine-tuning init failed: {e}")
        raise InternalServerError(f"fine-tuning init failed: {e}")
    finally:
        pass
        # conn.close() <-- ì œê±°ë¨

    job = FineTuneJob(job_id=job_id, category=category, request=body.model_dump())

    # ğŸ”¹ ì¦‰ì‹œ ì‹¤í–‰ì´ë©´ ì˜ˆì•½(startAt)ì€ **ë¬´ì‹œ**í•´ì„œ ì¤‘ë³µ ì‹¤í–‰ì„ ì›ì²œ ì°¨ë‹¨
    if body.startNow:
        def _launch():
            _run_training_inline(job, save_name_with_suffix)
        t = threading.Thread(target=_launch, daemon=True)
        t.start()
        logger.info(
            f"Fine-tuning started immediately jobId={job.job_id} category={category} base={body.baseModelName} "
            f"save={save_name_with_suffix} tuning={body.tuningType or 'QLORA'}"
        )
        return {"jobId": job_id, "started": True}
    else:
        # ì˜ˆì•½ ì‹¤í–‰ ë˜ëŠ” íì—ë§Œ ë“±ë¡
        if body.startAt:
            # ì˜ˆì•½ ì‹¤í–‰
            def _launch():
                _run_training_inline(job, save_name_with_suffix)

            # ì˜ˆì•½ ë”œë ˆì´ ì¬ê³„ì‚°
            delay_sec = 0.0
            try:
                scheduled_dt = datetime.fromisoformat(body.startAt)
                # timezone ì •ë³´ê°€ ì—†ìœ¼ë©´ KSTë¡œ ê°€ì •
                if scheduled_dt.tzinfo is None:
                    kst = timezone(timedelta(hours=9))
                    scheduled_dt = scheduled_dt.replace(tzinfo=kst)
                now_dt = _now_utc()
                delta = (scheduled_dt - now_dt).total_seconds()
                if delta > 1.0:
                    delay_sec = float(delta)
            except Exception:
                delay_sec = 0.0

            if delay_sec > 1.0:
                t = threading.Timer(delay_sec, _launch)
                t.daemon = True
                t.start()
                logger.info(
                    f"Fine-tuning scheduled jobId={job.job_id} at {scheduled_dt.isoformat()} category={category} base={body.baseModelName} save={save_name_with_suffix}"
                )
            else:
                # ì˜ˆì•½ ì‹œê°„ì´ ì´ë¯¸ ì§€ë‚¬ìœ¼ë©´ ì¦‰ì‹œ ì‹¤í–‰
                t = threading.Thread(target=_launch, daemon=True)
                t.start()
                logger.info(
                    f"Fine-tuning started (scheduled time passed) jobId={job.job_id} category={category} base={body.baseModelName} save={save_name_with_suffix}"
                )
        else:
            # íì—ë§Œ ë“±ë¡ (ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë‚˜ì¤‘ì— ì‹¤í–‰)
            try:
                _update_job_status(None, job_id, "queued", extras={"reserved": True, "reservedAt": _now_local_str()})
            finally:
                pass
            logger.info(
                f"Fine-tuning queued (not started) jobId={job.job_id} category={category} base={body.baseModelName} save={save_name_with_suffix}"
            )

    return {"jobId": job_id, "started": bool(body.startNow)}

def get_fine_tuning_status(job_id: str) -> Dict[str, Any]:
    with get_session() as s:
        # ORM ë²„ì „
        stmt = select(ORMJob).where(ORMJob.provider_job_id == job_id)
        row = s.execute(stmt).scalars().first()
        
        if not row:
            return {"error": "job not found", "jobId": job_id}
            
        metrics = {}
        if row.metrics:
            try:
                metrics = json.loads(row.metrics) or {}
            except Exception:
                metrics = {}

        # Liveness check
        row_status = row.status
        try:
            if row_status == "running":
                hb = metrics.get("heartbeatAt")
                if hb:
                    from dateutil import parser as dtparser
                    last = dtparser.parse(hb)
                    now = _now_utc()
                    if (now - last).total_seconds() > FT_HEARTBEAT_TIMEOUT_SEC:
                        fail_job(job_id, "stale heartbeat")
                        row_status = "failed"
        except Exception:
            pass

        return {
            "jobId": row.provider_job_id,
            "status": row_status,
            "learningProgress": int(metrics.get("learningProgress", 0)),
            "roughScore": int(metrics.get("roughScore", 0)),
            "rouge1F1": metrics.get("rouge1F1"),
            "saveProgress": int(metrics.get("saveProgress", 0)),
            "saveStage": metrics.get("saveStage"),
            "error": metrics.get("error"),
        }

def list_feedback_datasets() -> dict:
    """
    ./storage/train_data ì•ˆì—ì„œ íŒŒì¼ëª… íŒ¨í„´
    'feedback_{task}_p{prompt}.csv'ì— ë§¤ì¹­ë˜ëŠ” ëª¨ë“  CSVë¥¼ í…ŒìŠ¤í¬ë³„ë¡œ ë°˜í™˜.
    ë°˜í™˜ ê²½ë¡œëŠ” ìƒëŒ€ê²½ë¡œ('./storage/train_data/...')ë¥¼ ì œê³µí•œë‹¤.
    """
    REL_ROOT = "./storage/train_data"

    try:
        names = sorted(os.listdir(TRAIN_DATA_ROOT))
    except FileNotFoundError:
        names = []

    entries = []
    for name in names:
        m = _FEEDBACK_FILE_RE.match(name)
        if not m:
            continue
        task = m.group(1).lower()
        prompt = int(m.group(2))
        abs_path = os.path.join(TRAIN_DATA_ROOT, name)
        if not os.path.isfile(abs_path):
            continue
        st = os.stat(abs_path)
        mtime_dt = datetime.fromtimestamp(st.st_mtime)
        entries.append({
            "task": task,                               # qna | doc_gen | summary
            "file": name,                               # ex) feedback_qna_p0.csv
            "prompt": prompt,                           # ì •ìˆ˜ pê°’
            "bytes": st.st_size,                        # íŒŒì¼ í¬ê¸°
            "mtime": mtime_dt.strftime("%Y-%m-%d %H:%M:%S"),
            "mtime_iso": mtime_dt.isoformat(),
            "path": f"{REL_ROOT}/{name}",               # ìƒëŒ€ê²½ë¡œ (Docker ê³ ë ¤)
            "downloadUrl": f"/v1/admin/llm/feedback-datasets?file={quote_plus(name)}",
        })

    groups = {"qna": [], "doc_gen": [], "summary": []}
    for e in entries:
        groups[e["task"]].append(e)
    for k in groups:
        groups[k].sort(key=lambda x: x["prompt"])

    return {
        "root": REL_ROOT,
        "pattern": "feedback_{task}_p{prompt}.csv",
        "total": len(entries),
        "counts": {k: len(v) for k, v in groups.items()},
        "groups": groups,
    }

def resolve_feedback_download(file: str) -> tuple[str, str]:
    """
    ë‹¤ìš´ë¡œë“œìš© íŒŒì¼ ê²€ì¦/í•´ê²°:
    - basenameë§Œ í—ˆìš© (ê²½ë¡œ íƒˆì¶œ ë°©ì§€)
    - íŒŒì¼ëª… íŒ¨í„´ í™•ì¸
    - ./storage/train_data ë‚´ë¶€ ì¡´ì¬ í™•ì¸
    ì„±ê³µ ì‹œ: (abs_path, filename) ë°˜í™˜
    """
    if os.path.basename(file) != file:
        raise BadRequestError("basenameë§Œ í—ˆìš©í•©ë‹ˆë‹¤.")
    m = _FEEDBACK_FILE_RE.match(file)
    if not m:
        raise BadRequestError("ì˜ëª»ëœ íŒŒì¼ëª… í˜•ì‹ì…ë‹ˆë‹¤. (feedback_{task}_p{n}.csv)")
    abs_path = os.path.join(TRAIN_DATA_ROOT, file)
    if not os.path.isfile(abs_path):
        # ë¼ìš°í„°ì—ì„œ 404ë¡œ ë§¤í•‘í•˜ê¸° ìœ„í•´ í‘œì¤€ ì˜ˆì™¸ ì‚¬ìš©
        raise FileNotFoundError(f"not found in {TRAIN_DATA_ROOT}: {file}")
    return abs_path, file
